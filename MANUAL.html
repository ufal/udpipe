<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="generator" content="http://txt2tags.org">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>UDPipe</title>
</head>
<body>

<div class="header" id="header">
<h1>UDPipe</h1>
<h2>Version 1.0.0</h2>
</div>

<div class="toc">

  <ol>
  <li><a href="#introduction">Introduction</a>
  </li>
  <li><a href="#online">Online</a>
    <ul>
    <li><a href="#online_demo">2.1. Online Demo</a>
    </li>
    <li><a href="#web_service">2.2. Web Service</a>
    </li>
    </ul>
  </li>
  <li><a href="#release">Release</a>
    <ul>
    <li><a href="#download">3.1. Download</a>
      <ul>
      <li><a href="#language_models">3.1.1. Language Models</a>
      </li>
      </ul>
    </li>
    <li><a href="#license">3.2. License</a>
    </li>
    <li><a href="#platforms_and_requirements">3.3. Platforms and Requirements</a>
    </li>
    </ul>
  </li>
  <li><a href="#instalation">UDPipe Installation</a>
    <ul>
    <li><a href="#requirements">4.1. Requirements</a>
    </li>
    <li><a href="#compilation">4.2. Compilation</a>
      <ul>
      <li><a href="#compilation_platforms">4.2.1. Platforms</a>
      </li>
      <li><a href="#compilation_further_details">4.2.2. Further Details</a>
      </li>
      </ul>
    </li>
    <li><a href="#other_language_bindings">4.3. Other language bindings</a>
      <ul>
      <li><a href="#csharp_installation">4.3.1. C#</a>
      </li>
      <li><a href="#java_installation">4.3.2. Java</a>
      </li>
      <li><a href="#perl_installation">4.3.3. Perl</a>
      </li>
      <li><a href="#python_installation">4.3.4. Python</a>
      </li>
      </ul>
    </li>
    </ul>
  </li>
  <li><a href="#users_manual">UDPipe User's Manual</a>
    <ul>
    <li><a href="#universal_dependencies_12_models">5.1. Universal Dependencies 1.2 Models</a>
      <ul>
      <li><a href="#universal_dependencies_12_models_download">5.1.1. Download</a>
      </li>
      <li><a href="#universal_dependencies_12_models_acknowledgements">5.1.2. Acknowledgements</a>
      </li>
      <li><a href="#universal_dependencies_12_models_description">5.1.3. Model Description</a>
      </li>
      <li><a href="#universal_dependencies_12_models_performance">5.1.4. Model Performance</a>
      </li>
      </ul>
    </li>
    <li><a href="#run_udpipe">5.2. Running UDPipe</a>
      <ul>
      <li><a href="#run_udpipe_tokenizer">5.2.1. Tokenizer</a>
      </li>
      <li><a href="#run_udpipe_input">5.2.2. Input Formats</a>
      </li>
      <li><a href="#run_udpipe_tagger">5.2.3. Tagger</a>
      </li>
      <li><a href="#run_udpipe_parser">5.2.4. Dependency Parsing</a>
      </li>
      <li><a href="#run_udpipe_output">5.2.5. Output Formats</a>
      </li>
      </ul>
    </li>
    <li><a href="#udpipe_server">5.3. Running the UDPipe REST Server</a>
    </li>
    <li><a href="#model_training">5.4. Training UDPipe Models</a>
      <ul>
      <li><a href="#model_training_reusing_components">5.4.1. Reusing Components from Existing Models</a>
      </li>
      <li><a href="#model_training_random_search">5.4.2. Random Hyperparameter Search</a>
      </li>
      <li><a href="#model_training_tokenizer">5.4.3. Tokenizer</a>
      </li>
      <li><a href="#model_training_tagger">5.4.4. Tagger</a>
      </li>
      <li><a href="#model_training_parser">5.4.5. Parser</a>
      </li>
      <li><a href="#udpipe_accuracy">5.4.6. Measuring Model Accuracy</a>
      </li>
      </ul>
    </li>
    </ul>
  </li>
  <li><a href="#api_reference">UDPipe API Reference</a>
    <ul>
    <li><a href="#versioning">6.1. UDPipe Versioning</a>
    </li>
    <li><a href="#string_piece">6.2. Struct string_piece</a>
    </li>
    <li><a href="#word">6.3. Class word</a>
    </li>
    <li><a href="#multiword_token">6.4. Class multiword_token</a>
    </li>
    <li><a href="#empty_node">6.5. Class empty_node</a>
    </li>
    <li><a href="#sentence">6.6. Class sentence</a>
      <ul>
      <li><a href="#sentence_empty">6.6.1. sentence::empty()</a>
      </li>
      <li><a href="#sentence_clear">6.6.2. sentence::clear()</a>
      </li>
      <li><a href="#sentence_add_word">6.6.3. sentence::add_word()</a>
      </li>
      <li><a href="#sentence_set_head">6.6.4. sentence:set_head()</a>
      </li>
      <li><a href="#sentence_unlink_all_words">6.6.5. sentence::unlink_all_words()</a>
      </li>
      </ul>
    </li>
    <li><a href="#input_format">6.7. Class input_format</a>
      <ul>
      <li><a href="#input_format_read_block">6.7.1. input_format::read_block()</a>
      </li>
      <li><a href="#input_format_reset_document">6.7.2. input_format::reset_document()</a>
      </li>
      <li><a href="#input_format_set_text">6.7.3. input_format::set_text()</a>
      </li>
      <li><a href="#input_format_next_sentence">6.7.4. input_format::next_sentence()</a>
      </li>
      <li><a href="#input_format_new_input_format">6.7.5. input_format::new_input_format()</a>
      </li>
      <li><a href="#input_format_new_conllu_input_format">6.7.6. input_format::new_conllu_input_format()</a>
      </li>
      <li><a href="#input_format_new_horizontal_input_format">6.7.7. input_format::new_horizontal_input_format()</a>
      </li>
      <li><a href="#input_format_new_vertical_input_format">6.7.8. input_format::new_vertical_input_format()</a>
      </li>
      <li><a href="#input_format_new_presegmented_tokenizer">6.7.9. input_format::new_presegmented_tokenizer()</a>
      </li>
      </ul>
    </li>
    <li><a href="#output_format">6.8. Class output_format</a>
      <ul>
      <li><a href="#output_format_write_sentence">6.8.1. output_format::write_sentence()</a>
      </li>
      <li><a href="#output_format_finish_document">6.8.2. output_format::finish_document()</a>
      </li>
      <li><a href="#output_format_new_output_format">6.8.3. output_format::new_output_format()</a>
      </li>
      <li><a href="#output_format_new_conllu_output_format">6.8.4. output_format::new_conllu_output_format()</a>
      </li>
      <li><a href="#output_format_new_matxin_output_format">6.8.5. output_format::new_matxin_output_format()</a>
      </li>
      <li><a href="#output_format_new_horizontal_output_format">6.8.6. output_format::new_horizontal_output_format()</a>
      </li>
      <li><a href="#output_format_new_vertical_output_format">6.8.7. output_format::new_vertical_output_format()</a>
      </li>
      </ul>
    </li>
    <li><a href="#model">6.9. Class model</a>
      <ul>
      <li><a href="#model_load_cstring">6.9.1. model::load(const char*)</a>
      </li>
      <li><a href="#model_load_istream">6.9.2. model::load(istream&amp;)</a>
      </li>
      <li><a href="#model_new_tokenizer">6.9.3. model::new_tokenizer()</a>
      </li>
      <li><a href="#model_tag">6.9.4. model::tag()</a>
      </li>
      <li><a href="#model_parse">6.9.5. model::parse()</a>
      </li>
      </ul>
    </li>
    <li><a href="#pipeline">6.10. Class pipeline</a>
      <ul>
      <li><a href="#pipeline_set_model">6.10.1. pipeline::set_model()</a>
      </li>
      <li><a href="#pipeline_set_input">6.10.2. pipeline::set_input()</a>
      </li>
      <li><a href="#pipeline_set_tagger">6.10.3. pipeline::set_tagger()</a>
      </li>
      <li><a href="#pipeline_set_parser">6.10.4. pipeline::set_parser()</a>
      </li>
      <li><a href="#pipeline_set_output">6.10.5. pipeline::set_output()</a>
      </li>
      <li><a href="#pipeline_process">6.10.6. pipeline::process()</a>
      </li>
      </ul>
    </li>
    <li><a href="#trainer">6.11. Class trainer</a>
      <ul>
      <li><a href="#trainer_train">6.11.1. trainer::train()</a>
      </li>
      </ul>
    </li>
    <li><a href="#evaluator">6.12. Class evaluator</a>
      <ul>
      <li><a href="#evaluator_set_model">6.12.1. evaluator::set_model()</a>
      </li>
      <li><a href="#evaluator_set_tokenizer">6.12.2. evaluator::set_tokenizer()</a>
      </li>
      <li><a href="#evaluator_set_tagger">6.12.3. evaluator::set_tagger()</a>
      </li>
      <li><a href="#evaluator_set_parser">6.12.4. evaluator::set_parser()</a>
      </li>
      <li><a href="#evaluator_evaluate">6.12.5. evaluator::evaluate()</a>
      </li>
      </ul>
    </li>
    <li><a href="#version">6.13. Class version</a>
      <ul>
      <li><a href="#version_current">6.13.1. version::current</a>
      </li>
      </ul>
    </li>
    <li><a href="#cpp_bindings_api">6.14. C++ Bindings API</a>
      <ul>
      <li><a href="#bindings_helper_structures">6.14.1. Helper Structures</a>
      </li>
      <li><a href="#bindings_main_classes">6.14.2. Main Classes</a>
      </li>
      </ul>
    </li>
    <li><a href="#csharp_bindings">6.15. C# Bindings</a>
    </li>
    <li><a href="#java_bindings">6.16. Java Bindings</a>
    </li>
    <li><a href="#perl_bindings">6.17. Perl Bindings</a>
    </li>
    <li><a href="#python_bindings">6.18. Python Bindings</a>
    </li>
    </ul>
  </li>
  <li><a href="#contact">Contact</a>
  </li>
  <li><a href="#udpipe_acknowledgements">Acknowledgements</a>
    <ul>
    <li><a href="#publications">8.1. Publications</a>
    </li>
    <li><a href="#bibtex_for_referencing">8.2. Bibtex for Referencing</a>
    </li>
    <li><a href="#persistent_identifier">8.3. Persistent Identifier</a>
    </li>
    </ul>
  </li>
  </ol>

</div>
<div class="body" ID="body">

<a id="introduction" name="introduction"></a>
<h1>1. Introduction</h1>

<p>
UDPipe is an trainable pipeline for tokenization, tagging, lemmatization and
dependency parsing of CoNLL-U files. UDPipe is language-agnostic and can be trained given
only annotated data in CoNLL-U format. Trained models are provided for
nearly all UD treebanks. UDPipe is available as a binary, as a library for
C++, Python, Perl, Java, C#, and as a web service.
</p>
<p>
UDPipe is a free software under
<a href="http://www.mozilla.org/MPL/2.0/">Mozilla Public License 2.0</a> and the linguistic models
are free for non-commercial use and distributed under
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a> license, although for some
models the original data used to create the model may impose additional
licensing conditions. UDPipe is versioned using <a href="http://semver.org/">Semantic Versioning</a>.
</p>
<p>
Copyright 2016 by Institute of Formal and Applied Linguistics, Faculty of
Mathematics and Physics, Charles University in Prague, Czech Republic.
</p>

<a id="online" name="online"></a>
<h1>2. Online</h1>

<a id="online_demo" name="online_demo"></a>
<h2>2.1. Online Demo</h2>

<p>
<a href="http://lindat.cz">LINDAT/CLARIN</a> hosts <a href="http://lindat.mff.cuni.cz/services/udpipe/">UDPipe Online Demo</a>.
</p>

<a id="web_service" name="web_service"></a>
<h2>2.2. Web Service</h2>

<p>
<a href="http://lindat.cz">LINDAT/CLARIN</a> also hosts <a href="http://lindat.mff.cuni.cz/services/udpipe/api-reference.php">UDPipe Web Service</a>.
</p>

<a id="release" name="release"></a>
<h1>3. Release</h1>

<a id="download" name="download"></a>
<h2>3.1. Download</h2>

<p>
UDPipe releases are available on <a href="http://github.com/ufal/udpipe">GitHub</a>, either as
a pre-compiled binary package, or source code only. The binary package contains Linux,
Windows and OS X binaries, Java bindings binary, C# bindings binary, and source
code of UDPipe and all language bindings). While the binary
packages do not contain compiled Python or Perl bindings, packages for those
languages are available in standard package repositories, i.e. on PyPI and CPAN.
</p>

<ul>
<li><a href="http://github.com/ufal/udpipe/releases/latest">Latest release</a>
</li>
<li><a href="http://github.com/ufal/udpipe/releases">All releases</a>, <a href="https://github.com/ufal/udpipe/blob/master/CHANGES">Changelog</a>
</li>
</ul>

<a id="language_models" name="language_models"></a>
<h3>3.1.1. Language Models</h3>

<p>
To use UDpipe, a language model is needed. The language models are available
from <a href="http://www.lindat.cz">LINDAT/CLARIN</a> infrastructure and described further
in the
<a href="#users_manual">UDPipe User's Manual</a>.
Currently the following language models are available:
</p>

<ul>
<li>Universal Dependencies 1.2 Models: <a href="http://hdl.handle.net/11234/1-1659">udpipe-ud1.2-160523</a> (<a href="http://ufal.mff.cuni.cz/udpipe/users-manual#universal_dependencies_12_models">documentation</a>)
</li>
</ul>

<a id="license" name="license"></a>
<h2>3.2. License</h2>

<p>
UDPipe is an open-source project and is freely available for non-commercial
purposes. The library is distributed under
<a href="http://www.mozilla.org/MPL/2.0/">Mozilla Public License 2.0</a> and the associated models and data
under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>, although
for some models the original data used to create the model may impose
additional licensing conditions.
</p>
<p>
If you use this tool for scientific work, please give credit to us by
referencing <a href="#bibtex_for_referencing">Straka et al. 2016</a> and
<a href="http://ufal.mff.cuni.cz/udpipe">UDPipe website</a>.
</p>

<a id="platforms_and_requirements" name="platforms_and_requirements"></a>
<h2>3.3. Platforms and Requirements</h2>

<p>
UDpipe is available as a standalone tool and as a library for Linux/Windows/OS
X. It does not require any additional libraries. As any supervised machine
learning tool, it needs trained linguistic models.
</p>

<a id="instalation" name="instalation"></a>
<h1>4. UDPipe Installation</h1>

<p>
UDPipe releases are available on <a href="http://github.com/ufal/udpipe">GitHub</a>, either as
a pre-compiled binary package, or source code only. The binary package contains Linux,
Windows and OS X binaries, Java bindings binary, C# bindings binary, and source
code of UDPipe and all language bindings. While the binary
packages do not contain compiled Python or Perl bindings, packages for those
languages are available in standard package repositories, i.e. on PyPI and CPAN.
</p>
<p>
To use UDPipe, a language model is needed.
<a href="http://ufal.mff.cuni.cz/udpipe#language_models">Here is a list of available language models</a>.
</p>
<p>
If you want to compile UDPipe manually, sources are available on on
<a href="http://github.com/ufal/udpipe">GitHub</a>, both in the
<a href="http://github.com/ufal/udpipe/releases">pre-compiled binary package releases</a>
and in the repository itself.
</p>

<a id="requirements" name="requirements"></a>
<h2>4.1. Requirements</h2>

<ul>
<li><code>G++ 4.7</code> or newer, <code>clang 3.2</code> or newer, Visual C++ 2015 or newer
</li>
<li><code>make</code>
</li>
<li><code>SWIG 2.0.5</code> or newer for language bindings other than <code>C++</code>
</li>
</ul>

<a id="compilation" name="compilation"></a>
<h2>4.2. Compilation</h2>

<p>
To compile UDPipe, run <code>make</code> in the <code>src</code> directory.
</p>
<p style="margin-bottom:0">
Make targets and options:
</p>
<ul style="margin-top:0">
<li><code>exe</code>: compile the binaries (default)
</li>
<li><code>server</code>: compile the REST server
</li>
<li><code>lib</code>: compile the static library
</li>
<li><code>BITS=32</code> or <code>BITS=64</code>: compile for specified 32-bit or 64-bit architecture instead of the default one
</li>
<li><code>MODE=release</code>: create release build which statically links the C++ runtime and uses LTO
</li>
<li><code>MODE=debug</code>: create debug build
</li>
<li><code>MODE=profile</code>: create profile build
</li>
</ul>

<a id="compilation_platforms" name="compilation_platforms"></a>
<h3>4.2.1. Platforms</h3>

<p style="margin-bottom:0">
Platform can be selected using one of the following options:
</p>
<ul style="margin-top:0">
<li><code>PLATFORM=linux</code>, <code>PLATFORM=linux-gcc</code>: gcc compiler on Linux operating system, default on Linux
</li>
<li><code>PLATFORM=linux-clang</code>: clang compiler on Linux, must be selected manually
</li>
<li><code>PLATFORM=osx</code>, <code>PLATFORM=osx-clang</code>: clang compiler on OS X, default on OS X; <code>BITS=32+64</code> enables multiarch build
</li>
<li><code>PLATFORM=win</code>, <code>PLATFORM=win-gcc</code>: gcc compiler on Windows (TDM-GCC is well tested), default on Windows
</li>
<li><code>PLATFORM=win-vs</code>: Visual C++ 2015 compiler on Windows, must be selected manually; note that the
  <code>cl.exe</code> compiler must be already present in <code>PATH</code> and corresponding <code>BITS=32</code> or <code>BITS=64</code>
  must be specified
</li>
</ul>

<p>
Either POSIX shell or Windows CMD can be used as shell, it is detected automatically.
</p>

<a id="compilation_further_details" name="compilation_further_details"></a>
<h3>4.2.2. Further Details</h3>

<p>
UDPipe uses <a href="http://github.com/ufal/cpp_builtem">C++ BuilTem system</a>,
please refer to its manual if interested in all supported options.
</p>

<a id="other_language_bindings" name="other_language_bindings"></a>
<h2>4.3. Other language bindings</h2>

<a id="csharp_installation" name="csharp_installation"></a>
<h3>4.3.1. C#</h3>

<p>
Binary C# bindings are available in UDPipe binary packages.
</p>
<p>
To compile C# bindings manually, run <code>make</code> in the <code>bindings/csharp</code>
directory, optionally with the options described in UDPipe Installation.
</p>

<a id="java_installation" name="java_installation"></a>
<h3>4.3.2. Java</h3>

<p>
Binary Java bindings are available in UDPipe binary packages.
</p>
<p>
To compile Java bindings manually, run <code>make</code> in the <code>bindings/java</code>
directory, optionally with the options described in UDPipe Installation.
Java 6 and newer is supported.
</p>
<p style="margin-bottom:0">
The Java installation specified in the environment variable <code>JAVA_HOME</code> is
used.  If the environment variable does not exist, the <code>JAVA_HOME</code> can be
specified using
</p>
<pre style="margin-top:0">
make JAVA_HOME=path_to_Java_installation
</pre>

<a id="perl_installation" name="perl_installation"></a>
<h3>4.3.3. Perl</h3>

<p>
The Perl bindings are available as <code>Ufal-UDPipe</code> package on CPAN.
</p>
<p>
To compile Perl bindings manually, run <code>make</code> in the <code>bindings/perl</code>
directory, optionally with the options described in UDPipe Installation.
Perl 5.10 and later is supported.
</p>
<p style="margin-bottom:0">
Path to the include headers of the required Perl version must be specified
in the <code>PERL_INCLUDE</code> variable using
</p>
<pre style="margin-top:0">
make PERL_INCLUDE=path_to_Perl_includes
</pre>

<a id="python_installation" name="python_installation"></a>
<h3>4.3.4. Python</h3>

<p>
The Python bindings are available as <code>ufal.udpipe</code> package on PyPI.
</p>
<p>
To compile Python bindings manually, run <code>make</code> in the <code>bindings/python</code>
directory, optionally with options described in UDPipe Installation. Both
Python 2.6+ and Python 3+ are supported.
</p>
<p style="margin-bottom:0">
Path to the include headers of the required Python version must be specified
in the <code>PYTHON_INCLUDE</code> variable using
</p>
<pre style="margin-top:0">
make PYTHON_INCLUDE=path_to_Python_includes
</pre>

<a id="users_manual" name="users_manual"></a>
<h1>5. UDPipe User's Manual</h1>

<p>
Like any supervised machine learning tool, UDPipe needs a trained linguistic model.
This section describes the available language models and also the commandline
tools and interfaces.
</p>

<a id="universal_dependencies_12_models" name="universal_dependencies_12_models"></a>
<h2>5.1. Universal Dependencies 1.2 Models</h2>

<p>
Universal Dependencies 1.2 Models are distributed under the
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a> licence.
The models are based solely on
<a href="http://hdl.handle.net/11234/1-1548">Universal Dependencies 1.2</a> treebanks.
The models work in UDPipe version 1.0.
</p>
<p>
Universal Dependencies 1.2 Models are versioned according to the date released
in the format <code>YYMMDD</code>, where <code>YY</code>, <code>MM</code> and <code>DD</code> are two-digit
representation of year, month and day, respectively. The latest version is 160523.
</p>

<a id="universal_dependencies_12_models_download" name="universal_dependencies_12_models_download"></a>
<h3>5.1.1. Download</h3>

<p>
The latest version 160523 of the Czech MorphoDiTa models can be downloaded
from <a href="http://hdl.handle.net/11234/1-1659">LINDAT/CLARIN repository</a>.
</p>

<a id="universal_dependencies_12_models_acknowledgements" name="universal_dependencies_12_models_acknowledgements"></a>
<h3>5.1.2. Acknowledgements</h3>

<p>
This work has been partially supported and has been using language resources
and tools developed, stored and distributed by the LINDAT/CLARIN project of the
Ministry of Education, Youth and Sports of the Czech Republic (project <i>LM2015071</i>).
</p>
<p>
The models were trained on <a href="http://hdl.handle.net/11234/1-1548">Universal Dependencies 1.2</a> treebanks.
</p>
<p>
For the UD treebanks which do not contain original plain text version,
raw text is used to train the tokenizer instead. The plain texts
were taken from the <a href="http://hdl.handle.net/11858/00-097C-0000-0022-6133-9">W2C &ndash; Web to Corpus</a>.
</p>

<a id="universal_dependencies_12_models_publications" name="universal_dependencies_12_models_publications"></a>
<h4>5.1.2.1. Publications</h4>

<ul>
<li>(Straka et al. 2016) Straka Milan, Hajič Jan, Straková Jana. <i>UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing.</i> LREC 2016, Portorož, Slovenia, May 2016.
</li>
</ul>

<a id="universal_dependencies_12_models_description" name="universal_dependencies_12_models_description"></a>
<h3>5.1.3. Model Description</h3>

<p>
The Universal Dependencies 1.2 models contain 36 models, each consisting of
a tokenizer, tagger, lemmatizer and dependency parser, all trained using
the UD data. The model for Japanese is missing, because we do not have
the license for the required corpus of Mainichi Shinbun 1995.
</p>
<p>
The tokenizer is trained using the <code>SpaceAfter=No</code> features. If the features
are not present in the data, they can be filled in using raw text in the
language in question (surprisingly, quite little data suffices, we use 500kB).
</p>
<p>
The tagger, lemmatizer and parser are trained using gold UD data.
</p>
<p>
Details about model architecture and training process can be found in the
(Straka et al. 2016) paper.
</p>

<a id="universal_dependencies_12_models_performance" name="universal_dependencies_12_models_performance"></a>
<h3>5.1.4. Model Performance</h3>

<p>
We present the tagger, lemmatizer and parser performance, measured
on the testing portion of the data. Only the segmentation and the
tokenization of the testing data is retained before evaluation.
Therefore, the dependency parser is evaluated without gold POS tags.
</p>

<table border="1">
<tr>
<th>Treebank</th>
<th>UPOS</th>
<th>XPOS</th>
<th>Feats</th>
<th>All Tags</th>
<th>Lemma</th>
<th>UAS</th>
<th>LAS</th>
</tr>
<tr>
<td>Ancient Greek</td>
<td align="right">91.1%</td>
<td align="right">77.8%</td>
<td align="right">88.7%</td>
<td align="right">77.7%</td>
<td align="right">86.9%</td>
<td align="right">68.1%</td>
<td align="right">61.6%</td>
</tr>
<tr>
<td>Ancient Greek-PROIEL</td>
<td align="right">96.7%</td>
<td align="right">96.4%</td>
<td align="right">89.3%</td>
<td align="right">88.4%</td>
<td align="right">93.4%</td>
<td align="right">75.8%</td>
<td align="right">69.6%</td>
</tr>
<tr>
<td>Arabic</td>
<td align="right">98.8%</td>
<td align="right">97.7%</td>
<td align="right">97.8%</td>
<td align="right">97.6%</td>
<td align="center">-</td>
<td align="right">80.4%</td>
<td align="right">75.6%</td>
</tr>
<tr>
<td>Basque</td>
<td align="right">93.3%</td>
<td align="center">-</td>
<td align="right">87.2%</td>
<td align="right">85.4%</td>
<td align="right">93.5%</td>
<td align="right">74.8%</td>
<td align="right">69.5%</td>
</tr>
<tr>
<td>Bulgarian</td>
<td align="right">97.8%</td>
<td align="right">94.8%</td>
<td align="right">94.4%</td>
<td align="right">93.1%</td>
<td align="right">94.6%</td>
<td align="right">89.0%</td>
<td align="right">84.2%</td>
</tr>
<tr>
<td>Croatian</td>
<td align="right">94.9%</td>
<td align="center">-</td>
<td align="right">85.5%</td>
<td align="right">85.0%</td>
<td align="right">93.1%</td>
<td align="right">78.6%</td>
<td align="right">71.0%</td>
</tr>
<tr>
<td>Czech</td>
<td align="right">98.4%</td>
<td align="right">93.2%</td>
<td align="right">92.6%</td>
<td align="right">92.2%</td>
<td align="right">97.8%</td>
<td align="right">86.9%</td>
<td align="right">83.0%</td>
</tr>
<tr>
<td>Danish</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="right">94.8%</td>
<td align="right">93.6%</td>
<td align="right">95.2%</td>
<td align="right">78.6%</td>
<td align="right">74.8%</td>
</tr>
<tr>
<td>Dutch</td>
<td align="right">89.7%</td>
<td align="right">88.7%</td>
<td align="right">91.2%</td>
<td align="right">86.4%</td>
<td align="right">88.9%</td>
<td align="right">78.1%</td>
<td align="right">70.7%</td>
</tr>
<tr>
<td>English</td>
<td align="right">94.5%</td>
<td align="right">93.8%</td>
<td align="right">95.4%</td>
<td align="right">92.5%</td>
<td align="right">97.0%</td>
<td align="right">84.2%</td>
<td align="right">80.6%</td>
</tr>
<tr>
<td>Estonian</td>
<td align="right">88.0%</td>
<td align="right">73.7%</td>
<td align="right">80.0%</td>
<td align="right">73.6%</td>
<td align="right">77.0%</td>
<td align="right">79.9%</td>
<td align="right">71.5%</td>
</tr>
<tr>
<td>Finnish</td>
<td align="right">94.9%</td>
<td align="right">96.0%</td>
<td align="right">93.2%</td>
<td align="right">92.1%</td>
<td align="right">86.8%</td>
<td align="right">81.0%</td>
<td align="right">76.5%</td>
</tr>
<tr>
<td>Finnish-FTB</td>
<td align="right">94.0%</td>
<td align="right">91.6%</td>
<td align="right">93.3%</td>
<td align="right">91.2%</td>
<td align="right">89.1%</td>
<td align="right">81.5%</td>
<td align="right">76.9%</td>
</tr>
<tr>
<td>French</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="right">82.8%</td>
<td align="right">78.4%</td>
</tr>
<tr>
<td>German</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="right">78.2%</td>
<td align="right">72.2%</td>
</tr>
<tr>
<td>Gothic</td>
<td align="right">95.5%</td>
<td align="right">95.7%</td>
<td align="right">88.0%</td>
<td align="right">86.3%</td>
<td align="right">93.4%</td>
<td align="right">76.4%</td>
<td align="right">68.2%</td>
</tr>
<tr>
<td>Greek</td>
<td align="right">97.3%</td>
<td align="right">97.3%</td>
<td align="right">92.8%</td>
<td align="right">91.7%</td>
<td align="right">94.8%</td>
<td align="right">80.3%</td>
<td align="right">76.5%</td>
</tr>
<tr>
<td>Hebrew</td>
<td align="right">94.9%</td>
<td align="right">94.9%</td>
<td align="right">91.3%</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="right">82.6%</td>
<td align="right">76.8%</td>
</tr>
<tr>
<td>Hindi</td>
<td align="right">95.8%</td>
<td align="right">94.8%</td>
<td align="right">90.2%</td>
<td align="right">87.7%</td>
<td align="right">98.0%</td>
<td align="right">91.7%</td>
<td align="right">87.5%</td>
</tr>
<tr>
<td>Hungarian</td>
<td align="right">92.6%</td>
<td align="center">-</td>
<td align="right">89.9%</td>
<td align="right">88.9%</td>
<td align="right">86.9%</td>
<td align="right">77.0%</td>
<td align="right">70.6%</td>
</tr>
<tr>
<td>Indonesian</td>
<td align="right">93.5%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">93.5%</td>
<td align="center">-</td>
<td align="right">79.9%</td>
<td align="right">73.3%</td>
</tr>
<tr>
<td>Irish</td>
<td align="right">91.8%</td>
<td align="right">90.3%</td>
<td align="right">79.4%</td>
<td align="right">76.6%</td>
<td align="right">87.3%</td>
<td align="right">74.4%</td>
<td align="right">66.1%</td>
</tr>
<tr>
<td>Italian</td>
<td align="right">97.2%</td>
<td align="right">97.0%</td>
<td align="right">97.1%</td>
<td align="right">96.2%</td>
<td align="right">97.7%</td>
<td align="right">88.6%</td>
<td align="right">85.8%</td>
</tr>
<tr>
<td>Latin</td>
<td align="right">91.2%</td>
<td align="right">75.8%</td>
<td align="right">79.3%</td>
<td align="right">75.6%</td>
<td align="right">79.9%</td>
<td align="right">57.1%</td>
<td align="right">46.7%</td>
</tr>
<tr>
<td>Latin-ITT</td>
<td align="right">98.8%</td>
<td align="right">94.0%</td>
<td align="right">94.6%</td>
<td align="right">93.8%</td>
<td align="right">98.3%</td>
<td align="right">79.9%</td>
<td align="right">76.4%</td>
</tr>
<tr>
<td>Latin-PROIEL</td>
<td align="right">96.4%</td>
<td align="right">96.0%</td>
<td align="right">88.9%</td>
<td align="right">88.2%</td>
<td align="right">95.3%</td>
<td align="right">75.3%</td>
<td align="right">68.3%</td>
</tr>
<tr>
<td>Norwegian</td>
<td align="right">97.2%</td>
<td align="center">-</td>
<td align="right">95.5%</td>
<td align="right">94.7%</td>
<td align="right">96.9%</td>
<td align="right">86.7%</td>
<td align="right">84.1%</td>
</tr>
<tr>
<td>Old Church Slavonic</td>
<td align="right">95.3%</td>
<td align="right">95.1%</td>
<td align="right">89.1%</td>
<td align="right">88.2%</td>
<td align="right">92.9%</td>
<td align="right">80.6%</td>
<td align="right">73.4%</td>
</tr>
<tr>
<td>Persian</td>
<td align="right">97.0%</td>
<td align="right">96.3%</td>
<td align="right">96.5%</td>
<td align="right">96.2%</td>
<td align="center">-</td>
<td align="right">83.8%</td>
<td align="right">79.4%</td>
</tr>
<tr>
<td>Polish</td>
<td align="right">95.8%</td>
<td align="right">84.0%</td>
<td align="right">84.1%</td>
<td align="right">83.8%</td>
<td align="right">92.8%</td>
<td align="right">86.3%</td>
<td align="right">79.6%</td>
</tr>
<tr>
<td>Portuguese</td>
<td align="right">97.6%</td>
<td align="right">92.3%</td>
<td align="right">95.3%</td>
<td align="right">92.0%</td>
<td align="right">97.8%</td>
<td align="right">85.8%</td>
<td align="right">81.9%</td>
</tr>
<tr>
<td>Romanian</td>
<td align="right">89.0%</td>
<td align="right">81.0%</td>
<td align="right">82.3%</td>
<td align="right">81.0%</td>
<td align="right">75.3%</td>
<td align="right">68.6%</td>
<td align="right">56.9%</td>
</tr>
<tr>
<td>Slovenian</td>
<td align="right">95.7%</td>
<td align="right">88.2%</td>
<td align="right">88.6%</td>
<td align="right">87.5%</td>
<td align="right">95.0%</td>
<td align="right">84.1%</td>
<td align="right">80.3%</td>
</tr>
<tr>
<td>Spanish</td>
<td align="right">95.3%</td>
<td align="center">-</td>
<td align="right">95.9%</td>
<td align="right">93.4%</td>
<td align="right">96.3%</td>
<td align="right">84.2%</td>
<td align="right">80.3%</td>
</tr>
<tr>
<td>Swedish</td>
<td align="right">95.8%</td>
<td align="right">93.9%</td>
<td align="right">94.8%</td>
<td align="right">93.2%</td>
<td align="right">95.5%</td>
<td align="right">81.4%</td>
<td align="right">77.1%</td>
</tr>
<tr>
<td>Tamil</td>
<td align="right">85.9%</td>
<td align="right">80.8%</td>
<td align="right">84.3%</td>
<td align="right">80.2%</td>
<td align="right">88.0%</td>
<td align="right">67.2%</td>
<td align="right">58.8%</td>
</tr>
</table>

<a id="run_udpipe" name="run_udpipe"></a>
<h2>5.2. Running UDPipe</h2>

<p style="margin-bottom:0">
Probably the most common usage of UDPipe is to tokenize, tag and parse input using
</p>
<pre style="margin-top:0">
udpipe --tokenize --tag --parse udpipe_model
</pre>

<p>
The input is assumed to be in UTF-8 encoding and can be either already tokenized
and segmented, or it can be a plain text which is tokenized and segmented automatically.
</p>
<p>
Any number of files can be specified after the <code>udpipe_model</code> and if no
file is given, input is read from standard input. The output is by default
saved to standard output, but if <code>--outfile=name</code> is used, it is saved
to the given file name. The output file name can contain a <code>{}</code>, which is
replaced by a base name of the processed file (i.e., without directories
and an extension).
</p>
<p style="margin-bottom:0">
The full command syntax of running UDPipe is
</p>
<pre style="margin-top:0">
udpipe [options] udpipe_model file ...
Options: --input=[conllu|horizontal|vertical]
         --outfile=output file template
         --output=[conllu|horizontal|vertical]
         --tokenize (perform tokenization)
         --tokenizer=tokenizer options, implies --tokenize
         --tag (perform tagging)
         --tagger=tagger options, implies --tag
         --parse (perform parsing)
         --parser=parser options, implies --parse
</pre>

<a id="run_udpipe_tokenizer" name="run_udpipe_tokenizer"></a>
<h3>5.2.1. Tokenizer</h3>

<p>
If the <code>--tokenize</code> input is supplied, the input is assumed to be
plain text and is tokenized using model tokenizer. Additional arguments to the
tokenizer might be specified using <code>--tokenizer=data</code> option (which implies
<code>--tokenize</code>).
</p>

<a id="run_udpipe_input" name="run_udpipe_input"></a>
<h3>5.2.2. Input Formats</h3>

<p style="margin-bottom:0">
If the tokenizer is not used, the input format is specified using the
<code>--input</code> option. Currently supported input formats are:
</p>
<ul style="margin-top:0">
<li><code>conllu</code> (default): the <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
</li>
<li><code>horizontal</code>: each sentence on a separate line, with tokens separated by spaces
</li>
<li><code>vertical</code>: each token on a separate line, with an empty line denoting end of sentence;
  only the first space-separated word is used as a token, the rest of the line is ignored
</li>
</ul>

<a id="run_udpipe_tagger" name="run_udpipe_tagger"></a>
<h3>5.2.3. Tagger</h3>

<p>
If the <code>--tag</code> input is supplied, the input is POS tagged lemmatized
using the model tagger. Additional arguments to the tagger might be
specified using <code>--tagger=data</code> option (which implies <code>--tag</code>).
</p>

<a id="run_udpipe_parser" name="run_udpipe_parser"></a>
<h3>5.2.4. Dependency Parsing</h3>

<p>
If the <code>--parse</code> input is supplied, the input is parsed using
the model dependency parser.  Additional arguments to the parser might be
specified using <code>--parser=data</code> option (which implies <code>--parse</code>).
</p>

<a id="run_udpipe_output" name="run_udpipe_output"></a>
<h3>5.2.5. Output Formats</h3>

<p style="margin-bottom:0">
The output format is specified using the <code>--output</code> option. Currently
supported output formats are:
</p>
<ul style="margin-top:0">
<li><code>conllu</code> (default): the <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
</li>
<li><code>horizontal</code>: each sentence on a separate line, with words separated by a single space
</li>
<li><code>vertical</code>: each word on a separate line, with an empty line denoting end of sentence
</li>
</ul>

<a id="udpipe_server" name="udpipe_server"></a>
<h2>5.3. Running the UDPipe REST Server</h2>

<p>
UDPipe also provides REST server binary <code>udpipe_server</code>.
The binary uses <a href="http://github.com/ufal/microrestd">MicroRestD</a> as a REST
server implementation and provides
<a href="http://lindat.mff.cuni.cz/services/udpipe/api-reference.php">UDPipe REST API</a>.
</p>
<p style="margin-bottom:0">
The full command syntax of <code>udpipe_server</code> is
</p>
<pre style="margin-top:0">
udpipe_server [options] port (rest_id model_file acknowledgements)*
Options: --daemon
</pre>

<p>
The <code>udpipe_server</code> can run either in foreground or in background (when
<code>--daemon</code> is used). The specified model files are loaded during start and
kept in memory all the time. This behaviour may change in future to load the
models on demand.
</p>

<a id="model_training" name="model_training"></a>
<h2>5.4. Training UDPipe Models</h2>

<p style="margin-bottom:0">
Custom UDPipe models can be trained using the following syntax:
</p>
<pre style="margin-top:0">
udpipe --train model.output [--heldout=heldout_data] training_file ...
</pre>

<p>
The training data should be in <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>.
</p>
<p>
By default three model components are trained &ndash; a tokenizer, tagger and
a parser.  Any subset of the model components can be trained and a model
component may be copied from an existing model.
</p>
<p>
The training options are specified for each model component separately
using the <code>--tokenizer</code>, <code>--tagger</code> and <code>--parser</code> option.
If a model component should not be trained, value <code>none</code> should
be used (e.g., <code>--tagger=none</code>).
</p>
<p>
The options are <code>name=value</code> pairs separated by a semicolon. The
value can be either a simple string value (ending by a semicolon),
file content specified as <code>name=file:filename</code>, or an arbitrary
string value specified as <code>name=data:length:value</code>, where the value
is exactly <code>length</code> bytes long.
</p>

<a id="model_training_reusing_components" name="model_training_reusing_components"></a>
<h3>5.4.1. Reusing Components from Existing Models</h3>

<p>
The model components (tagger, parser or tagger) can be reused from
existing models, by specifying <code>from_model=file:filename</code> option.
</p>

<a id="model_training_random_search" name="model_training_random_search"></a>
<h3>5.4.2. Random Hyperparameter Search</h3>

<p>
The default values of hyperparameters is set to the values
which were used the most during UD 1.2 models training, but if you
want to reach best performance, the hyperparameters must be tuned.
</p>
<p>
Apart from manual grid search, UDPipe can perform a simple random search.
You can perform the random search by repeatedly training UDPipe
(preferably in parallel, most likely on different computers)
while specifying different training run number &ndash; some of the
hyperparameters (chosen by us; but if you specify their value
on command line, it is not modified) change their value on different
training runs. The pseudorandom sequences of hyperparameters
are of course deterministic.
</p>
<p>
The training run can be specified by providing <code>run=number</code> option
to a model component. The run number 1 is the default one (with best
hyperparameters for the UD 1.2 models), runs 2 and more randomize
the hyperparameters.
</p>

<a id="model_training_tokenizer" name="model_training_tokenizer"></a>
<h3>5.4.3. Tokenizer</h3>

<p>
The tokenizer is trained using the <code>SpaceAfter=No</code> features in the CoNLL-U files.
If the feature is not present, a <i>detokenizer</i> can be used to guess
the <code>SpaceAfter=No</code> features according to a supplied plain text.
</p>
<p>
In order to use the detokenizer, use <code>detokenizer=file:filename_with_plaintext</code>
option. In UD 1.2 models, optimal performance is achieved with very small plain
texts &ndash; only 500kB.
</p>
<p style="margin-bottom:0">
The tokenizer recognizes the following options:
</p>
<ul style="margin-top:0">
<li><code>tokenize_url</code> (default 1): tokenize URLs and emails using a manually
    implemented recognizer
</li>
<li><code>allow_spaces</code> (default 1 if any token contains a space, 0 otherwise): allow tokens to contain spaces
</li>
<li><code>epochs</code> (default 100): the number of epochs to train the tokenizer for
</li>
<li><code>batch_size</code> (default 50): batch size used during tokenizer training
</li>
<li><code>learning_rate</code> (default 0.005): the learning rate used during tokenizer training
</li>
<li><code>dropout</code> (default 0.1): dropout used during tokenizer training
</li>
<li><code>early_stopping</code> (default 1 if heldout is given, 0 otherwise): perform
    early stopping, choosing training iteration maximizing sentences F1 score plus
    tokens F1 score on heldout data
</li>
</ul>

<p>
During random hyperparameter search, <code>batch_size</code> is chosen uniformly from <i>{50,100}</i>
and <code>learning_rate</code> logarithmically from <i>&lt;0.0005, 0.01)</i>.
</p>

<a id="model_training_tagger" name="model_training_tagger"></a>
<h3>5.4.4. Tagger</h3>

<p>
The tagging is currently performed using <a href="http://ufal.mff.cuni.cz/morphodita">MorphoDiTa</a>.
The UDPipe tagger consists of possibly several MorphoDiTa models, each tagging
some of the POS tags and/or lemmas.
</p>
<p>
By default, only one model is constructed, which generates all available tags (UPOS,
XPOS, Feats and Lemma). However, we found out during the UD 1.2 models training
that performance improves if one model tags the UPOS, XPOS and Feats tags, while the
other is performing lemmatization. Therefore, if you utilize two MorphoDiTa models,
by default the first one generates all tags and the second one performs lemmatization.
</p>
<p>
The number of MorphoDiTa models can be specified using <code>models=number</code> parameter.
All other parameters may be either generic for all models (<code>guesser_suffix_rules=5</code>),
or specific for a given model (<code>guesser_suffix_rules_2=6</code>), including the
<code>from_model</code> option (therefore, MorphoDiTa models can be trained separately
and then combined together to one UDPipe model).
</p>
<p>
Every model utilizes UPOS for disambiguation and the first model is the one producing
the UPOS tags on output.
</p>
<p style="margin-bottom:0">
The tagger recognizes the following options:
</p>
<ul style="margin-top:0">
<li><code>use_lemma</code> (default for the second model and also if there is only one model): use the
  lemma field internally to perform disambiguation; the lemma may be not outputted
</li>
<li><code>provide_lemma</code> (default for the second model and also if there is only one model):
  produce the disambiguated lemma on output
</li>
<li><code>use_xpostag</code> (default for the first model): use the
  XPOS tags internally to perform disambiguation; it may not be outputted
</li>
<li><code>provide_xpostag</code> (default for the first model): produce the disambiguated XPOS tag on output
</li>
<li><code>use_feats</code> (default for the first model): use the
  Feats internally to perform disambiguation; it may not be outputted
</li>
<li><code>provide_feats</code> (default for the first model): produce the disambiguated Feats field on output
</li>
<li><code>dictionary_max_form_analyses</code> (default 0 - unlimited): the number of
  maximum number of (most frequent) form analyses from UD training data that are to be
  kept in the morphological dictionary
</li>
<li><code>dictionary</code> (default empty): use given custom morphological dictionary, where every line contains
  5 tab-separated fields FORM, LEMMA, UPOSTAG, XPOSTAG and FEATS. Note that this dictionary
  data is appended to the dictionary created from UD training data, not replacing it.
</li>
<li><code>guesser_suffix_rules</code> (default 8): number of rules generated for every suffix
</li>
<li><code>guesser_prefixes_max</code> (default 4 if ``provide_lemma`, 0 otherwise): maximum
  number of form-generating prefixes to use in the guesser
</li>
<li><code>guesser_prefix_min_count</code> (default 10): minimum number of occurrences of form-generating
  prefix to consider using it in the guesser
</li>
<li><code>guesser_enrich_dictionary</code> (default 6 if no <code>dictionary</code> is passed, 0 otherwise): number of rules generated for forms present
  in training data (assuming that the analyses from the training data may not be all)
</li>
<li><code>iterations</code> (default 20): number of training iterations to perform
</li>
<li><code>early_stopping</code> (default 1 if heldout is given, 0 otherwise): perform
    early stopping, choosing training iteration maximizing tagging accuracy on heldout data
</li>
<li><code>templates</code> (default <code>lemmatizer</code> for second model, <code>tagger</code> otherwise): MorphoDiTa
    feature templates to use, either <code>lemmatizer</code> which focuses more on lemmas, or
    <code>tagger</code> which focuses more on UPOS/XPOS/FEATS
</li>
</ul>

<p>
During random hyperparameter search, <code>guesser_suffix_rules</code> is chosen uniformly from
<i>{5,6,7,8,9,10,11,12}</i> and <code>guesser_enrich_dictionary</code> is chosen uniformly from
<i>{3,4,5,6,7,8,9,10}</i>.
</p>

<a id="model_training_parser" name="model_training_parser"></a>
<h3>5.4.5. Parser</h3>

<p>
The parsing is performed using <a href="http://ufal.mff.cuni.cz/parsito">Parsito</a>, which is a
transition-based parser using neural network classifier.
</p>
<p style="margin-bottom:0">
The transition-based systems can be configured by the following options:
</p>
<ul style="margin-top:0">
<li><code>transition_system</code> (default projective): which transition system to use for parsing (language dependant, you can choose according
  to language properties or try all and choose the best)
  <ul>
  <li><code>projective</code>: projective stack-based arc standard system with <code>shift</code>, <code>left_arc</code> and <code>right_arc</code> transitions
  </li>
  <li><code>swap</code>: fully non-projective system which extends <code>projective</code> system by adding <code>swap</code> transition
  </li>
  <li><code>link2</code>: partially non-projective system which extends <code>projective</code> system by adding <code>left_arc2</code> and <code>right_arc2</code> transitions
  </li>
  </ul>
</li>
<li><code>transition_oracle</code> (default dynamic/static_lazy_static whichever first is applicable): which transition oracle to use for the chosen <code>transition_system</code>:
  <ul>
  <li><code>transition_system=projective</code>: available oracles are <code>static</code> and <code>dynamic</code> (<code>dynamic</code> usually gives better results, but training time is slower)
  </li>
  <li><code>transition_system=swap</code>: available oracles are <code>static_eager</code> and <code>static_lazy</code> (<code>static_lazy</code> almost always gives better results)
  </li>
  <li><code>transition_system=link2</code>: only available oracle is <code>static</code>
  </li>
  </ul>
</li>
<li><code>structured_interval</code> (default 8): use search-based oracle in addition to the <code>translation_oracle</code> specified. This almost always gives better results, but makes training 2-3 times slower. For details, see the paper <i>Straka et al. 2015: Parsing Universal Dependency Treebanks using Neural Networks and Search-Based Oracle</i>
</li>
<li><code>single_root</code> (default 1): allow only single root when parsing, and make sure only root node has <code>root</code> deprel (note that training data are checked to be in this format)
</li>
</ul>

<p style="margin-bottom:0">
The Lemmas/UPOS/XPOS/FEATS used by parser are configured by:
</p>
<ul style="margin-top:0">
<li><code>use_gold_tags</code> (default 0): if false and a tagger exists, the
  Lemmas/UPOS/XPOS/FEATS for both the training and heldout data are generated
  by the tagger, otherwise they are taken from the gold data
</li>
</ul>

<p style="margin-bottom:0">
The embeddings used by the parser can be specified as follows:
</p>
<ul style="margin-top:0">
<li><code>embedding_upostag</code> (default 20): the dimension of the UPos embedding used in the parser
</li>
<li><code>embedding_feats</code> (default 20): the dimension of the Feats embedding used in the parser
</li>
<li><code>embedding_xpostag</code> (default 0): the dimension of the XPos embedding used in the parser
</li>
<li><code>embedding_form</code> (default 50): the dimension of the Form embedding used in the parser
</li>
<li><code>embedding_lemma</code> (default 0): the dimension of the Lemma embedding used in the parser
</li>
<li><code>embedding_deprel</code> (default 20): the dimension of the Deprel embedding used in the parser
</li>
<li><code>embedding_form_file</code>: pre-trained word embeddings created by <code>word2vec</code> can be optionally used;
    pretraining embeddings even on the UD data itself improves accuracy (we use <code>-cbow 0 -size 50 -window 10 -negative 5 -hs 0 -sample 1e-1 -threads 12 -binary 0 -iter 15 -min-count 2</code> options to pretrain on UD data)
</li>
<li><code>embedding_lemma_file</code>: pre-trained lemma embeddings created by <code>word2vec</code> can be optionally used;
</li>
</ul>

<p style="margin-bottom:0">
The neural network training options:
</p>
<ul style="margin-top:0">
<li><code>iterations</code> (default 10): number of training iterations to use
</li>
<li><code>hidden_layer</code> (default 200): the size of the hidden layer
</li>
<li><code>batch_size</code> (default 10): batch size used during neural network training
</li>
<li><code>learning_rate</code> (default 0.02): the learning rate used during neural network training
</li>
<li><code>learning_rate_final</code> (0.001): the final learning rate used during neural network training
</li>
<li><code>l2</code> (0.5): the L2 regularization used during neural network training
</li>
<li><code>early_stopping</code> (default 1 if heldout is given, 0 otherwise): perform
    early stopping, choosing training iteration maximizing LAS on heldout data
</li>
</ul>

<p>
During random hyperparameter search, <code>structured_interval</code> is chosen uniformly from
<i>{0,8,10}</i>, <code>learning_rate</code> is chosen logarithmically from <code>&lt;0.005,0.04)</code> and
<code>l2</code> is chosen uniformly from <code>&lt;0.2,0.6)</code>.
</p>

<a id="udpipe_accuracy" name="udpipe_accuracy"></a>
<h3>5.4.6. Measuring Model Accuracy</h3>

<p style="margin-bottom:0">
Measuring custom model accuracy can be performed by running:
</p>
<pre style="margin-top:0">
udpipe --accuracy [udpipe_options] udpipe_model file ...
</pre>

<p>
The command syntax is similar to the regular UDPipe operation, only
the input must be always in <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
and the <code>--input</code> and <code>--output</code> options are ignored.
</p>
<p>
If <code>--tokenize(r)</code> option is passed, tokenizer performance is evaluted
(using <code>SpaceAfter=No</code> features of the input file). If <code>--tag(ger)</code> and/or <code>--parse(r)</code>
options are passed, tagger and/or dependency parser performance is evaluated, respectively.
</p>

<a id="api_reference" name="api_reference"></a>
<h1>6. UDPipe API Reference</h1>

<p>
The UDPipe API is defined in header <code>udpipe.h</code> and resides in
<code>ufal::udpipe</code> namespace. The API allows only using existing models,
for custom model creation you have to use the <code>train_parser</code> binary.
</p>
<p>
The strings used in the UDPipe API are always UTF-8 encoded (except from
file paths, whose encoding is system dependent).
</p>

<a id="versioning" name="versioning"></a>
<h2>6.1. UDPipe Versioning</h2>

<p>
UDPipe is versioned using <a href="http://semver.org/">Semantic Versioning</a>.
Therefore, a version consists of three numbers <i>major.minor.patch</i>, optionally
followed by a hyphen and pre-release version info, with the following semantics:
</p>

<ul>
<li>Stable versions have no pre-release version info, development have non-empty
  pre-release version info.
</li>
<li>Two versions with the same <i>major.minor</i> have the same API with the same
  behaviour, apart from bugs. Therefore, if only <i>patch</i> is increased, the
  new version is only a bug-fix release.
</li>
<li>If two versions <i>v</i> and <i>u</i> have the same <i>major</i>, but <i>minor(v)</i> is
  greater than <i>minor(u)</i>, version <i>v</i> contains only additions to the API.
  In other words, the API of <i>u</i> is all present in <i>v</i> with the same
  behaviour (once again apart from bugs). It is therefore safe to upgrade to
  a newer UDPipe version with the same <i>major</i>.
</li>
<li>If two versions differ in <i>major</i>, their API may differ in any way.
</li>
</ul>

<p>
Models created by UDPipe have the same behaviour in all UDPipe
versions with same <i>major</i>, apart from obvious bugfixes. On the other hand,
models created from the same data by different <i>major.minor</i> UDPipe
versions may have different behaviour.
</p>

<a id="string_piece" name="string_piece"></a>
<h2>6.2. Struct string_piece</h2>

<pre>
struct string_piece {
  const char* str;
  size_t len;

  string_piece();
  string_piece(const char* str);
  string_piece(const char* str, size_t len);
  string_piece(const std::string&amp; str);
}
</pre>

<p>
The <a href="#string_piece"><code>string_piece</code></a> is used for efficient string passing. The string
referenced in <a href="#string_piece"><code>string_piece</code></a> is not owned by it, so users have to make sure
the referenced string exists as long as the <a href="#string_piece"><code>string_piece</code></a>.
</p>

<a id="word" name="word"></a>
<h2>6.3. Class word</h2>

<pre>
class word {
 public:
  int id;         // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  string form;    // form
  string lemma;   // lemma
  string upostag; // universal part-of-speech tag
  string xpostag; // language-specific part-of-speech tag
  string feats;   // list of morphological features
  int head;       // head, 0 is root, &lt;0 is undefined
  string deprel;  // dependency relation to the head
  string deps;    // secondary dependencies
  string misc;    // miscellaneous information

  vector&lt;int&gt; children;

  word(int id = -1, <A HREF="#string_piece">string_piece</A> form = string_piece());
};
</pre>

<p>
The <a href="#word"><code>word</code></a> class represents a sentence word.
The <a href="#word"><code>word</code></a> fields correspond to <a href="http://universaldependencies.org/docs/format.html">CoNLL-U fields</a>,
with the <code>children</code> field representing the opposite direction of
<code>head</code> links (the elements of the <code>children</code> array are in ascending order).
</p>

<a id="multiword_token" name="multiword_token"></a>
<h2>6.4. Class multiword_token</h2>

<pre>
class multiword_token {
 public:
  int id_first, id_last;
  string form;
  string misc;

  multiword_token(int id_first = -1, int id_last = -1, <A HREF="#string_piece">string_piece</A> form = string_piece(), <A HREF="#string_piece">string_piece</A> misc = string_piece());
};
</pre>

<p>
The <a href="#multiword_token"><code>multiword_token</code></a> represents a multi-word token
described in <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>.
The multi-word token references underlying words, it has a form and a misc field
(which may contain for example `SpaceAfter=No` feature). Other CoNLL-U word
fields are guaranteed to be empty.
</p>

<a id="empty_node" name="empty_node"></a>
<h2>6.5. Class empty_node</h2>

<pre>
class empty_node {
 public:
  int id;         // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  int index;      // index for the current id, should be numbered from 1, 0=undefined
  string form;    // form
  string lemma;   // lemma
  string upostag; // universal part-of-speech tag
  string xpostag; // language-specific part-of-speech tag
  string feats;   // list of morphological features
  string deps;    // secondary dependencies
  string misc;    // miscellaneous information

  empty_node(int id = -1, int index = 0) : id(id), index(index) {}
};
</pre>

<p>
The <a href="#empty_node"><code>empty_node</code></a> class represents an empty node from CoNLL-U 2.0,
with the fields corresponding to <a href="http://universaldependencies.org/docs/format.html">CoNLL-U fields</a>.
For a specified <code>id</code>, the <code>index</code> are numbered sequentially from 1.
</p>

<a id="sentence" name="sentence"></a>
<h2>6.6. Class sentence</h2>

<pre>
class sentence {
 public:
  sentence();

  vector&lt;<A HREF="#word">word</A>&gt; words;
  vector&lt;<A HREF="#multiword_token">multiword_token</A>&gt; multiword_tokens;
  vector&lt;empty_node&gt; empty_nodes;
  vector&lt;string&gt; comments;
  static const string root_form;

  bool <A HREF="#sentence_empty">empty</A>();
  void <A HREF="#sentence_clear">clear</A>();
  <A HREF="#word">word</A>&amp; <A HREF="#sentence_add_word">add_word</A>(<A HREF="#string_piece">string_piece</A> form = string_piece());
  void <A HREF="#sentence_set_head">set_head</A>(int id, int head, const string&amp; deprel);
  void <A HREF="#sentence_unlink_all_words">unlink_all_words</A>();
};
</pre>

<p style="margin-bottom:0">
The <a href="#sentence"><code>sentence</code></a> class represents a sentence <a href="http://universaldependencies.org/docs/format.html">CoNLL-U sentence</a>,
which consists of:
</p>
<ul style="margin-top:0">
<li>sequence of <a href="#word"><code>word</code></a>s stored in ascending order, with the first word
  (with index 0) always being a technical root with form <code>root_form</code>
</li>
<li>sequence of <a href="#multiword_token"><code>multiword_token</code></a>s also stored in ascending
  order
</li>
<li>comments
</li>
</ul>

<p>
Although you can manipulate the <code>words</code> directly, the
<a href="#sentence"><code>sentence</code></a> class offers several simple node manipulation methods.
</p>

<a id="sentence_empty" name="sentence_empty"></a>
<h3>6.6.1. sentence::empty()</h3>

<pre>
bool empty();
</pre>

<p>
Returns <code>true</code> if the sentence is empty. i.e., if it contains only a technical root node.
</p>

<a id="sentence_clear" name="sentence_clear"></a>
<h3>6.6.2. sentence::clear()</h3>

<pre>
void clear();
</pre>

<p>
Removes all words, multi-word tokens and comments (only the technical root <code>word</code> is kept).
</p>

<a id="sentence_add_word" name="sentence_add_word"></a>
<h3>6.6.3. sentence::add_word()</h3>

<pre>
<A HREF="#word">word</A>&amp; add_word(<A HREF="#string_piece">string_piece</A> form = string_piece());
</pre>

<p>
Adds a new word to the sentence. The new word has first unused <code>id</code>,
specified <code>form</code> and is not linked to any other node. Reference to the new
word is returned so that other fields can be also filled.
</p>

<a id="sentence_set_head" name="sentence_set_head"></a>
<h3>6.6.4. sentence:set_head()</h3>

<pre>
void set_head(int id, int head, const std::string&amp; deprel);
</pre>

<p>
Link the word <code>id</code> to the word <code>head</code>, with the specified dependency relation.
If the <code>head</code> is negative, the word <code>id</code> is unlinked from its current head,
if any.
</p>

<a id="sentence_unlink_all_words" name="sentence_unlink_all_words"></a>
<h3>6.6.5. sentence::unlink_all_words()</h3>

<pre>
void unlink_all_words();
</pre>

<p>
Unlink all words.
</p>

<a id="input_format" name="input_format"></a>
<h2>6.7. Class input_format</h2>

<pre>
class input_format {
 public:
  virtual ~input_format() {}

  virtual bool <A HREF="#input_format_read_block">read_block</A>(istream&amp; is, string&amp; block) const = 0;
  virtual void <A HREF="#input_format_reset_document">reset_document</A>() {};
  virtual void <A HREF="#input_format_set_text">set_text</A>(<A HREF="#string_piece">string_piece</A> text, bool make_copy = false) = 0;
  virtual bool <A HREF="#input_format_next_sentence">next_sentence</A>(<A HREF="#sentence">sentence</A>&amp; s, string&amp; error) = 0;

  // Static factory methods
  static <A HREF="#input_format">input_format</A>* <A HREF="#input_format_new_input_format">new_input_format</A>(const string&amp; name);
  static <A HREF="#input_format">input_format</A>* <A HREF="#input_format_new_conllu_input_format">new_conllu_input_format</A>();
  static <A HREF="#input_format">input_format</A>* <A HREF="#input_format_new_horizontal_input_format">new_horizontal_input_format</A>();
  static <A HREF="#input_format">input_format</A>* <A HREF="#input_format_new_vertical_input_format">new_vertical_input_format</A>();

  static <A HREF="#input_format">input_format</A>* <A HREF="#input_format_new_presegmented_tokenizer">new_presegmented_tokenizer</A>(<A HREF="#input_format">input_format</A>* tokenizer);
};
</pre>

<p>
The <a href="#input_format"><code>input_format</code></a> class allows loading sentences in various formats.
</p>
<p>
Th class instances may store internal state and are not thread-safe.
</p>

<a id="input_format_read_block" name="input_format_read_block"></a>
<h3>6.7.1. input_format::read_block()</h3>

<pre>
virtual bool read_block(istream&amp; is, string&amp; block) const = 0;
</pre>

<p>
Read a portion of input, which is guaranteed to contain only complete
sentences. Such portion is usually a paragraph (text followed by an empty line)
or a line, but it may be more complex (i.e., in a XML-like format).
</p>

<a id="input_format_reset_document" name="input_format_reset_document"></a>
<h3>6.7.2. input_format::reset_document()</h3>

<pre>
virtual void reset_document() {};
</pre>

<p>
Resets the <a href="#input_format"><code>input_format</code></a> instance state. Such state
is needed not only for remembering unprocessed text of the last
<a href="#input_format_set_text"><code>set_text</code></a> call, but also for correct inter-block
state tracking (for example in a tokenizer which returns document-level offsets,
or in a tokenizer which tracks inter-sentence spaces &ndash; if you pass only spaces
to <a href="#input_format_set_text"><code>set_text</code></a>, these spaces has to accumulate and be
returned as preceeding spaces of the next sentence).
</p>

<a id="input_format_set_text" name="input_format_set_text"></a>
<h3>6.7.3. input_format::set_text()</h3>

<pre>
virtual void set_text(<A HREF="#string_piece">string_piece</A> text, bool make_copy = false) = 0;
</pre>

<p>
Set the text from which the sentences will be read.
</p>
<p>
If <code>make_copy</code> is <code>false</code>, only a reference to the given text is
stored and the user has to make sure it exists until the instance
is destroyed or <code>set_text</code> is called again. If <code>make_copy</code>
is <code>true</code>, a copy of the given text is made and retained until the
instance is destroyed or <code>set_text</code> is called again.
</p>

<a id="input_format_next_sentence" name="input_format_next_sentence"></a>
<h3>6.7.4. input_format::next_sentence()</h3>

<pre>
virtual bool next_sentence(<A HREF="#sentence">sentence</A>&amp; s, string&amp; error) = 0;
</pre>

<p>
Try reading another sentence from the text specified by
<A HREF="#input_format_set_text"><code>set_text</A>. Returns ``true</code> if the sentence was
read and <code>false</code> if the text ended or there was a read error. The latter
two conditions can be distinguished by the <code>error</code> parameter &ndash; if it is
empty, the text ended, if it is nonempty, it contains a description of the
read error.
</p>

<a id="input_format_new_input_format" name="input_format_new_input_format"></a>
<h3>6.7.5. input_format::new_input_format()</h3>

<pre>
static <A HREF="#input_format">input_format</A>* new_input_format(const string&amp; name);
</pre>

<p style="margin-bottom:0">
Create new <a href="#input_format"><code>input_format</code></a> instance, given its name.
The following input formats are currently supported:
</p>
<ul style="margin-top:0">
<li><code>conllu</code>: return the <a href="#input_format_new_conllu_input_format"><code>new_conllu_input_format</code></a>
</li>
<li><code>horizontal</code>: return the <a href="#input_format_new_horizontal_input_format"><code>new_horizontal_input_format</code></a>
</li>
<li><code>vertical</code>: return the <a href="#input_format_new_vertical_input_format"><code>new_vertical_input_format</code></a>
</li>
</ul>

<p>
The new instance must be deleted after use.
</p>

<a id="input_format_new_conllu_input_format" name="input_format_new_conllu_input_format"></a>
<h3>6.7.6. input_format::new_conllu_input_format()</h3>

<pre>
static <A HREF="#input_format">input_format</A>* new_conllu_input_format();
</pre>

<p>
Create <a href="#input_format"><code>input_format</code></a> instance which loads sentences
in the <a href="http://universaldependencies.github.io/docs/format.html">CoNLL-U format</a>.
The new instance must be deleted after use.
</p>

<a id="input_format_new_horizontal_input_format" name="input_format_new_horizontal_input_format"></a>
<h3>6.7.7. input_format::new_horizontal_input_format()</h3>

<pre>
static <A HREF="#input_format">input_format</A>* new_horizontal_input_format();
</pre>

<p>
Create <a href="#input_format"><code>input_format</code></a> instance which loads forms from a simple
horizontal format &ndash; each sentence on a line, with word forms separated by spaces.
The new instance must be deleted after use.
</p>

<a id="input_format_new_vertical_input_format" name="input_format_new_vertical_input_format"></a>
<h3>6.7.8. input_format::new_vertical_input_format()</h3>

<pre>
static <A HREF="#input_format">input_format</A>* new_vertical_input_format();
</pre>

<p>
Create <a href="#input_format"><code>input_format</code></a> instance which loads forms from a simple
vertical format &ndash; each word on a line, with empty line denoting end of sentence.
The new instance must be deleted after use.
</p>

<a id="input_format_new_presegmented_tokenizer" name="input_format_new_presegmented_tokenizer"></a>
<h3>6.7.9. input_format::new_presegmented_tokenizer()</h3>

<pre>
static <A HREF="#input_format">input_format</A>* new_presegmented_tokenizer(<A HREF="#input_format">input_format</A>* tokenizer);
</pre>

<p>
Create <a href="#input_format"><code>input_format</code></a> instance which acts as a tokenizer
adapter &ndash; given a tokenizer which segments anywhere, it creates a tokenizer
which segments on newline characters (by calling the tokenizer on individual lines,
and if the tokenizer segments in the middle of the line, it calls it repeatedly
and merges the results).
</p>
<p>
The new instance must be deleted after use. Note that the new instance
<i>takes ownership</i> of the given <code>tokenizer</code> and <i>deletes</i> it during
its own deletion.
</p>

<a id="output_format" name="output_format"></a>
<h2>6.8. Class output_format</h2>

<pre>
class output_format {
 public:
  virtual ~output_format() {}

  virtual void <A HREF="#output_format_write_sentence">write_sentence</A>(const <A HREF="#sentence">sentence</A>&amp; s, ostream&amp; os) = 0;
  virtual void <A HREF="#output_format_finish_document">finish_document</A>(ostream&amp; os) {};

  // Static factory methods
  static <A HREF="#output_format">output_format</A>* <A HREF="#output_format_new_output_format">new_output_format</A>(const string&amp; name);
  static <A HREF="#output_format">output_format</A>* <A HREF="#output_format_new_conllu_output_format">new_conllu_output_format</A>();
  static <A HREF="#output_format">output_format</A>* <A HREF="#output_format_new_matxin_output_format">new_matxin_output_format</A>();
  static <A HREF="#output_format">output_format</A>* <A HREF="#output_format_new_horizontal_output_format">new_horizontal_output_format</A>();
  static <A HREF="#output_format">output_format</A>* <A HREF="#output_format_new_vertical_output_format">new_vertical_output_format</A>();
};
</pre>

<p>
The <a href="#output_format"><code>output_format</code></a> class allows printing sentences
in various formats.
</p>
<p>
The class instances may store internal state and are not thread-safe.
</p>

<a id="output_format_write_sentence" name="output_format_write_sentence"></a>
<h3>6.8.1. output_format::write_sentence()</h3>

<pre>
virtual void write_sentence(const <A HREF="#sentence">sentence</A>&amp; s, ostream&amp; os) = 0;
</pre>

<p>
Write given <a href="#sentence"><code>sentence</code></a> to the given output stream.
</p>
<p>
When the output format requires document-level markup, it is written
automatically when the first sentence is written using this
<a href="#output_format"><code>output_format</code></a> instance (or after
<a href="#output_format_finish_document"><code>finish_document</code></a> call).
</p>

<a id="output_format_finish_document" name="output_format_finish_document"></a>
<h3>6.8.2. output_format::finish_document()</h3>

<pre>
virtual void finish_document(ostream&amp; os) {};
</pre>

<p>
When the output format requires document-level markup, write
the end-of-document mark and reset the <a href="#output_format"><code>output_format</code></a>
instance state (i.e., the next <a href="#write_sentence"><code>write_sentence</code></a>
will write start-of-document mark).
</p>

<a id="output_format_new_output_format" name="output_format_new_output_format"></a>
<h3>6.8.3. output_format::new_output_format()</h3>

<pre>
static <A HREF="#output_format">output_format</A>* new_output_format(const string&amp; name);
</pre>

<p style="margin-bottom:0">
Create new <a href="#output_format"><code>output_format</code></a> instance, given its name.
The following output formats are currently supported:
</p>
<ul style="margin-top:0">
<li><code>conllu</code>: return the <a href="#output_format_new_conllu_output_format"><code>new_conllu_output_format</code></a>
</li>
<li><code>matxin</code>: return the <a href="#output_format_new_matxin_output_format"><code>new_matxin_output_format</code></a>
</li>
<li><code>horizontal</code>: return the <a href="#output_format_new_horizontal_output_format"><code>new_horizontal_output_format</code></a>
</li>
<li><code>vertical</code>: return the <a href="#output_format_new_vertical_output_format"><code>new_vertical_output_format</code></a>
</li>
</ul>

<p>
The new instance must be deleted after use.
</p>

<a id="output_format_new_conllu_output_format" name="output_format_new_conllu_output_format"></a>
<h3>6.8.4. output_format::new_conllu_output_format()</h3>

<pre>
static <A HREF="#output_format">output_format</A>* new_conllu_output_format();
</pre>

<p>
Creates <a href="#output_format"><code>output_format</code></a> instance for writing sentences
in the <a href="http://universaldependencies.github.io/docs/format.html">CoNLL-U format</a>.
The new instance must be deleted after use.
</p>

<a id="output_format_new_matxin_output_format" name="output_format_new_matxin_output_format"></a>
<h3>6.8.5. output_format::new_matxin_output_format()</h3>

<pre>
static <A HREF="#output_format">output_format</A>* new_matxin_output_format();
</pre>

<p style="margin-bottom:0">
Creates <a href="#output_format"><code>output_format</code></a> instance for writing sentences
in the Matxin format &ndash; UDPipe produces a XML with the following DTD:
</p>
<pre style="margin-top:0">
&lt;!ELEMENT    corpus     (SENTENCE*)&gt;
&lt;!ELEMENT    SENTENCE   (NODE*)&gt;
&lt;!ATTLIST    SENTENCE    ord           CDATA        #REQUIRED
                         alloc         CDATA        #REQUIRED&gt;
&lt;!ELEMENT    NODE   (NODE*)&gt;
&lt;!ATTLIST    NODE        ord           CDATA        #REQUIRED
                         alloc         CDATA        #REQUIRED
                         form          CDATA        #REQUIRED
                         lem           CDATA        #REQUIRED
                         mi            CDATA        #REQUIRED
                         si            CDATA        #REQUIRED
                         sub           CDATA        #REQUIRED&gt;
</pre>

<p>
The new instance must be deleted after use.
</p>

<a id="output_format_new_horizontal_output_format" name="output_format_new_horizontal_output_format"></a>
<h3>6.8.6. output_format::new_horizontal_output_format()</h3>

<pre>
static <A HREF="#output_format">output_format</A>* new_horizontal_output_format();
</pre>

<p>
Creates <a href="#output_format"><code>output_format</code></a> instance for writing sentences
in a simple horizontal format &ndash; each sentence on a line, with word forms separated
by spaces. The new instance must be deleted after use.
</p>

<a id="output_format_new_vertical_output_format" name="output_format_new_vertical_output_format"></a>
<h3>6.8.7. output_format::new_vertical_output_format()</h3>

<pre>
static <A HREF="#output_format">output_format</A>* new_vertical_output_format();
</pre>

<p>
Creates <a href="#output_format"><code>output_format</code></a> instance for writing sentences
in a simple vertical format &ndash; each word form on a line, with empty line
denoting end of sentence. The new instance must be deleted after use.
</p>

<a id="model" name="model"></a>
<h2>6.9. Class model</h2>

<pre>
class model {
 public:
  virtual ~model() {}

  static <A HREF="#model">model</A>* <A HREF="#model_load_cstring">load</A>(const char* fname);
  static <A HREF="#model">model</A>* <A HREF="#model_load_istream">load</A>(istream&amp; is);

  virtual <A HREF="#input_format">input_format</A>* <A HREF="#model_new_tokenizer">new_tokenizer</A>(const string&amp; options) const = 0;
  virtual bool <A HREF="#model_tag">tag</A>(<A HREF="#sentence">sentence</A>&amp; s, const string&amp; options, string&amp; error) const = 0;
  virtual bool <A HREF="#model_parse">parse</A>(<A HREF="#sentence">sentence</A>&amp; s, const string&amp; options, string&amp; error) const = 0;

  static const string DEFAULT;
  static const string TOKENIZER_PRESEGMENTED;
};
</pre>

<a id="model_load_cstring" name="model_load_cstring"></a>
<h3>6.9.1. model::load(const char*)</h3>

<pre>
static <A HREF="#model">model</A>* load(const char* fname);
</pre>

<a id="model_load_istream" name="model_load_istream"></a>
<h3>6.9.2. model::load(istream&amp;)</h3>

<pre>
static <A HREF="#model">model</A>* load(istream&amp; is);
</pre>

<a id="model_new_tokenizer" name="model_new_tokenizer"></a>
<h3>6.9.3. model::new_tokenizer()</h3>

<pre>
virtual <A HREF="#input_format">input_format</A>* new_tokenizer(const string&amp; options) const = 0;
</pre>

<a id="model_tag" name="model_tag"></a>
<h3>6.9.4. model::tag()</h3>

<pre>
virtual bool tag(<A HREF="#sentence">sentence</A>&amp; s, const string&amp; options, string&amp; error) const = 0;
</pre>

<a id="model_parse" name="model_parse"></a>
<h3>6.9.5. model::parse()</h3>

<pre>
virtual bool parse(<A HREF="#sentence">sentence</A>&amp; s, const string&amp; options, string&amp; error) const = 0;
</pre>

<a id="pipeline" name="pipeline"></a>
<h2>6.10. Class pipeline</h2>

<pre>
class pipeline {
 public:
  pipeline(const <A HREF="#model">model</A>* m, const string&amp; input, const string&amp; tagger, const string&amp; parser, const string&amp; output);

  void <A HREF="#pipeline_set_model">set_model</A>(const <A HREF="#model">model</A>* m);
  void <A HREF="#pipeline_set_input">set_input</A>(const string&amp; input);
  void <A HREF="#pipeline_set_tagger">set_tagger</A>(const string&amp; tagger);
  void <A HREF="#pipeline_set_parser">set_parser</A>(const string&amp; parser);
  void <A HREF="#pipeline_set_output">set_output</A>(const string&amp; output);

  bool <A HREF="#pipeline_process">process</A>(istream&amp; is, ostream&amp; os, string&amp; error) const;

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="pipeline_set_model" name="pipeline_set_model"></a>
<h3>6.10.1. pipeline::set_model()</h3>

<pre>
void set_model(const <A HREF="#model">model</A>* m);
</pre>

<a id="pipeline_set_input" name="pipeline_set_input"></a>
<h3>6.10.2. pipeline::set_input()</h3>

<pre>
void set_input(const string&amp; input);
</pre>

<a id="pipeline_set_tagger" name="pipeline_set_tagger"></a>
<h3>6.10.3. pipeline::set_tagger()</h3>

<pre>
void set_tagger(const string&amp; tagger);
</pre>

<a id="pipeline_set_parser" name="pipeline_set_parser"></a>
<h3>6.10.4. pipeline::set_parser()</h3>

<pre>
void set_parser(const string&amp; parser);
</pre>

<a id="pipeline_set_output" name="pipeline_set_output"></a>
<h3>6.10.5. pipeline::set_output()</h3>

<pre>
void set_output(const string&amp; output);
</pre>

<a id="pipeline_process" name="pipeline_process"></a>
<h3>6.10.6. pipeline::process()</h3>

<pre>
bool process(istream&amp; is, ostream&amp; os, string&amp; error) const;
</pre>

<a id="trainer" name="trainer"></a>
<h2>6.11. Class trainer</h2>

<pre>
class trainer {
 public:
  static bool <A HREF="#trainer_train">train</A>(const string&amp; method, const vector&lt;<A HREF="#sentence">sentence</A>&gt;&amp; train, const vector&lt;<A HREF="#sentence">sentence</A>&gt;&amp; heldout,
                    const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser,
                    ostream&amp; os, string&amp; error);

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="trainer_train" name="trainer_train"></a>
<h3>6.11.1. trainer::train()</h3>

<pre>
static bool train(const string&amp; method, const vector&lt;<A HREF="#sentence">sentence</A>&gt;&amp; train, const vector&lt;<A HREF="#sentence">sentence</A>&gt;&amp; heldout,
                  const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser,
                  ostream&amp; os, string&amp; error);
</pre>

<a id="evaluator" name="evaluator"></a>
<h2>6.12. Class evaluator</h2>

<pre>
class evaluator {
 public:
  evaluator(const <A HREF="#model">model</A>* m, const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser);

  void <A HREF="#evaluator_set_model">set_model</A>(const <A HREF="#model">model</A>* m);
  void <A HREF="#evaluator_set_tokenizer">set_tokenizer</A>(const string&amp; tokenizer);
  void <A HREF="#evaluator_set_tagger">set_tagger</A>(const string&amp; tagger);
  void <A HREF="#evaluator_set_parser">set_parser</A>(const string&amp; parser);

  bool <A HREF="#evaluator_evaluate">evaluate</A>(istream&amp; is, ostream&amp; os, string&amp; error) const;

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="evaluator_set_model" name="evaluator_set_model"></a>
<h3>6.12.1. evaluator::set_model()</h3>

<pre>
void set_model(const <A HREF="#model">model</A>* m);
</pre>

<a id="evaluator_set_tokenizer" name="evaluator_set_tokenizer"></a>
<h3>6.12.2. evaluator::set_tokenizer()</h3>

<pre>
void set_tokenizer(const string&amp; tokenizer);
</pre>

<a id="evaluator_set_tagger" name="evaluator_set_tagger"></a>
<h3>6.12.3. evaluator::set_tagger()</h3>

<pre>
void set_tagger(const string&amp; tagger);
</pre>

<a id="evaluator_set_parser" name="evaluator_set_parser"></a>
<h3>6.12.4. evaluator::set_parser()</h3>

<pre>
void set_parser(const string&amp; parser);
</pre>

<a id="evaluator_evaluate" name="evaluator_evaluate"></a>
<h3>6.12.5. evaluator::evaluate()</h3>

<pre>
bool evaluate(istream&amp; is, ostream&amp; os, string&amp; error) const;
</pre>

<a id="version" name="version"></a>
<h2>6.13. Class version</h2>

<pre>
class version {
 public:
  unsigned major;
  unsigned minor;
  unsigned patch;
  string prerelease;

  static <A HREF="#version">version</A> <A HREF="#version_current">current</A>();
};
</pre>

<p>
The <a href="#version"><code>version</code></a> class represents UDPipe version.
See <a href="#versioning">UDPipe Versioning</a> for more information.
</p>

<a id="version_current" name="version_current"></a>
<h3>6.13.1. version::current</h3>

<pre>
static <A HREF="#version">version</A> current();
</pre>

<p>
Returns current UDPipe version.
</p>

<a id="cpp_bindings_api" name="cpp_bindings_api"></a>
<h2>6.14. C++ Bindings API</h2>

<p>
Bindings for other languages than C++ are created using SWIG from the C++
bindings API, which is a slightly modified version of the native C++ API.
Main changes are replacement of <a href="#string_piece"><code>string_piece</code></a> type by native
strings and removal of methods using <code>istream</code>. Here is the C++ bindings API
declaration:
</p>

<a id="bindings_helper_structures" name="bindings_helper_structures"></a>
<h3>6.14.1. Helper Structures</h3>

<pre>
typedef vector&lt;int&gt; Children;

typedef vector&lt;string&gt; Comments;

class ProcessingError {
public:
  bool occurred();
  string message;
};

class Word {
 public:
  int id;         // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  string form;    // form
  string lemma;   // lemma
  string upostag; // universal part-of-speech tag
  string xpostag; // language-specific part-of-speech tag
  string feats;   // list of morphological features
  int head;       // head, 0 is root, &lt;0 is undefined
  string deprel;  // dependency relation to the head
  string deps;    // secondary dependencies
  string misc;    // miscellaneous information

  Children children;

  Word(int id = -1, const string&amp; form = string());
};
typedef vector&lt;Word&gt; Words;

class MultiwordToken {
 public:
  int idFirst, idLast;
  string form;
  string misc;

  MultiwordToken(int id_first = -1, int id_last = -1, const string&amp; form = string(), const string&amp; misc = string());
};
typedef vector&lt;MultiwordToken&gt; MultiwordTokens;

class EmptyNode {
 public:
  int id;          // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  int index;       // index for the current id, should be numbered from 1, 0=undefined
  string form;     // form
  string lemma;    // lemma
  string upostag;  // universal part-of-speech tag
  string xpostag;  // language-specific part-of-speech tag
  string feats;    // list of morphological features
  string deps;     // secondary dependencies
  string misc;     // miscellaneous information

  EmptyNode(int id = -1, int index = 0) : id(id), index(index) {}
};
typedef vector&lt;empty_node&gt; EmptyNodes;

class Sentence {
 public:
  Sentence();

  Words words;
  MultiwordTokens multiwordTokens;
  EmptyNodes emptyNodes;
  Comments comments;
  static const string rootForm;

  bool empty();
  void clear();
  virtual Word&amp; addWord(const char* form);
  void setHead(int id, int head, const string&amp; deprel);
  void unlinkAllWords();
};
typedef vector&lt;Sentence&gt; Sentences;
</pre>

<a id="bindings_main_classes" name="bindings_main_classes"></a>
<h3>6.14.2. Main Classes</h3>

<pre>
class InputFormat {
 public:
  virtual void resetDocument();
  virtual void setText(const char* text);
  virtual bool nextSentence(Sentence&amp; s, ProcessingError* error = nullptr);

  static InputFormat* newInputFormat(const string&amp; name);
  static InputFormat* newConlluInputFormat();
  static InputFormat* newHorizontalInputFormat();
  static InputFormat* newVerticalInputFormat();

  static InputFormat* newPresegmentedTokenizer(InputFormat tokenizer);
};

class OutputFormat {
 public:
  virtual string writeSentence(const Sentence&amp; s);
  virtual string finishDocument();

  static OutputFormat* newOutputFormat(const string&amp; name);
  static OutputFormat* newConlluOutputFormat();
  static OutputFormat* newMatxinOutputFormat();
  static OutputFormat* newHorizontalOutputFormat();
  static OutputFormat* newVerticalOutputFormat();
};

class Model {
 public:
  static Model* load(const char* fname);

  virtual InputFormat* newTokenizer(const string&amp; options) const;
  virtual bool tag(Sentence&amp; s, const string&amp; options, ProcessingError* error = nullptr) const;
  virtual bool parse(Sentence&amp; s, const string&amp; options, ProcessingError* error) const;

  static const string DEFAULT;
  static const string TOKENIZER_PRESEGMENTED;
};

class Pipeline {
 public:
  Pipeline(const Model* m, const string&amp; input, const string&amp; tagger, const string&amp; parser, const string&amp; output);

  void setModel(const Model* m);
  void setInput(const string&amp; input);
  void setTagger(const string&amp; tagger);
  void setParser(const string&amp; parser);
  void setOutput(const string&amp; output);

  string process(const string&amp; data, ProcessingError* error = nullptr) const;

  static const string DEFAULT;
  static const string NONE;
};

class Trainer {
 public:

  static string train(const string&amp; method, const Sentences&amp; train, const Sentences&amp; heldout,
                      const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser,
                      ProcessingError* error = nullptr);

  static const string DEFAULT;
  static const string NONE;
};

class Evaluator {
 public:
  Evaluator(const Model* m, const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser);

  void setModel(const Model* m);
  void setTokenizer(const string&amp; tokenizer);
  void setTagger(const string&amp; tagger);
  void setParser(const string&amp; parser);

  string evaluate(const string&amp; data, ProcessingError* error = nullptr) const;

  static const string DEFAULT;
  static const string NONE;
};

class Version {
 public:
  unsigned major;
  unsigned minor;
  unsigned patch;
  string prerelease;

  // Returns current version.
  static version current();
};
</pre>

<a id="csharp_bindings" name="csharp_bindings"></a>
<h2>6.15. C# Bindings</h2>

<p>
UDPipe library bindings is available in the <code>Ufal.UDPipe</code> namespace.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
The bindings requires native C++ library <code>libudpipe_csharp</code> (called
<code>udpipe_csharp</code> on Windows).
</p>

<a id="java_bindings" name="java_bindings"></a>
<h2>6.16. Java Bindings</h2>

<p>
UDPipe library bindings is available in the <code>cz.cuni.mff.ufal.udpipe</code>
package.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
Vectors do not have native Java interface, see
<code>cz.cuni.mff.ufal.udpipe.Words</code> class for reference. Also, class members
are accessible and modifiable using using <code>getField</code> and <code>setField</code>
wrappers.
</p>
<p>
The bindings require native C++ library <code>libudpipe_java</code> (called
<code>udpipe_java</code> on Windows). If the library is found in the current
directory, it is used, otherwise standard library search process is used.
The path to the C++ library can also be specified using static
<code>udpipe_java.setLibraryPath(String path)</code> call (before the first call
inside the C++ library, of course).
</p>

<a id="perl_bindings" name="perl_bindings"></a>
<h2>6.17. Perl Bindings</h2>

<p>
UDPipe library bindings is available in the
<a href="http://search.cpan.org/~straka/Ufal-UDPipe/"><code>Ufal::UDPipe</code></a> package.
The classes can be imported into the current namespace using the <code>:all</code>
export tag.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
Vectors do not have native Perl interface, see <code>Ufal::UDPipe::Words</code> for
reference. Static methods and enumerations are available only through the
module, not through object instance.
</p>

<a id="python_bindings" name="python_bindings"></a>
<h2>6.18. Python Bindings</h2>

<p>
UDPipe library bindings is available in the
<a href="http://pypi.python.org/pypi/ufal.udpipe"><code>ufal.udpipe</code></a> module.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
In Python 2, strings can be both <code>unicode</code> and UTF-8 encoded <code>str</code>, and the
library always produces <code>unicode</code>. In Python 3, strings must be only <code>str</code>.
</p>

<a id="contact" name="contact"></a>
<h1>7. Contact</h1>

<p style="margin-bottom:0">
Authors:
</p>
<ul style="margin-top:0">
<li><a href="http://ufal.mff.cuni.cz/milan-straka">Milan Straka</a>, <a href="mailto:straka@ufal.mff.cuni.cz">straka@ufal.mff.cuni.cz</a>
</li>
</ul>

<p>
<a href="http://ufal.mff.cuni.cz/udpipe">UDPipe website</a>.
</p>
<p>
<a href="http://hdl.handle.net/11234/1-1702">UDPipe LINDAT/CLARIN entry</a>.
</p>

<a id="udpipe_acknowledgements" name="udpipe_acknowledgements"></a>
<h1>8. Acknowledgements</h1>

<p>
This work has been using language resources developed and/or stored and/or distributed by the LINDAT/CLARIN project of the Ministry of Education of the Czech Republic (project <i>LM2010013</i>).
</p>
<p>
Acknowledgements for individual language models are listed in <a href="#users_manual">UDPipe User's Manual</a>.
</p>

<a id="publications" name="publications"></a>
<h2>8.1. Publications</h2>

<ul>
<li>(Straka et al. 2016) Straka Milan, Hajič Jan, Straková Jana. <i>UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing.</i> In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), Portorož, Slovenia, May 2016.
</li>
</ul>

<a id="bibtex_for_referencing" name="bibtex_for_referencing"></a>
<h2>8.2. Bibtex for Referencing</h2>

<pre>
@InProceedings{udpipe:2016,
  author    = {Straka, Milan and Haji\v{c}, Jan and Strakov\'{a}, Jana},
  title     = {{UDPipe:} Trainable Pipeline for Processing {CoNLL-U} Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing},
  booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},
  year      = {2016},
  month     = {May},
  date      = {23-28},
  location  = {Portorož, Slovenia},
  publisher = {European Language Resources Association (ELRA)},
  address   = {Paris, France},
  isbn      = {978-2-9517408-9-1},
  url       = {http://www.lrec-conf.org/proceedings/lrec2016/pdf/873_Paper.pdf},
}
</pre>

<a id="persistent_identifier" name="persistent_identifier"></a>
<h2>8.3. Persistent Identifier</h2>

<p>
If you prefer to reference UDPipe by a persistent identifier (PID),
you can use <code>http://hdl.handle.net/11234/1-1702</code>.
</p>
</div>

<!-- html code generated by txt2tags 2.6 (http://txt2tags.org) -->
<!-- cmdline: txt2tags -t html -\-toc -\-enum-title -o manual.html -C t2t_docsys/t2t_docsys_manual.conf manual.t2t -->
</body></html>
