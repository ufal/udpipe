<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<meta name="generator" content="http://txt2tags.org">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>UDPipe</title>
</head>
<body>

<div class="header" id="header">
<h1>UDPipe</h1>
<h2>Version 1.0.0</h2>
</div>

<div class="toc">

  <ol>
  <li><a href="#introduction">Introduction</a>
  </li>
  <li><a href="#online">Online</a>
    <ul>
    <li><a href="#online_demo">2.1. Online Demo</a>
    </li>
    <li><a href="#web_service">2.2. Web Service</a>
    </li>
    </ul>
  </li>
  <li><a href="#release">Release</a>
    <ul>
    <li><a href="#download">3.1. Download</a>
      <ul>
      <li><a href="#language_models">3.1.1. Language Models</a>
      </li>
      </ul>
    </li>
    <li><a href="#license">3.2. License</a>
    </li>
    <li><a href="#platforms_and_requirements">3.3. Platforms and Requirements</a>
    </li>
    </ul>
  </li>
  <li><a href="#instalation">UDPipe Installation</a>
    <ul>
    <li><a href="#requirements">4.1. Requirements</a>
    </li>
    <li><a href="#compilation">4.2. Compilation</a>
      <ul>
      <li><a href="#compilation_platforms">4.2.1. Platforms</a>
      </li>
      <li><a href="#compilation_further_details">4.2.2. Further Details</a>
      </li>
      </ul>
    </li>
    <li><a href="#other_language_bindings">4.3. Other language bindings</a>
      <ul>
      <li><a href="#csharp_installation">4.3.1. C#</a>
      </li>
      <li><a href="#java_installation">4.3.2. Java</a>
      </li>
      <li><a href="#perl_installation">4.3.3. Perl</a>
      </li>
      <li><a href="#python_installation">4.3.4. Python</a>
      </li>
      </ul>
    </li>
    </ul>
  </li>
  <li><a href="#users_manual">UDPipe User's Manual</a>
    <ul>
    <li><a href="#universal_dependencies_12_models">5.1. Universal Dependencies 1.2 Models</a>
      <ul>
      <li><a href="#universal_dependencies_12_models_download">5.1.1. Download</a>
      </li>
      <li><a href="#universal_dependencies_12_models_acknowledgements">5.1.2. Acknowledgements</a>
      </li>
      <li><a href="#universal_dependencies_12_models_description">5.1.3. Model Description</a>
      </li>
      <li><a href="#universal_dependencies_12_models_performance">5.1.4. Model Performance</a>
      </li>
      </ul>
    </li>
    <li><a href="#run_udpipe">5.2. Running UDPipe</a>
      <ul>
      <li><a href="#run_udpipe_tokenizer">5.2.1. Tokenizer</a>
      </li>
      <li><a href="#run_udpipe_input">5.2.2. Input Formats</a>
      </li>
      <li><a href="#run_udpipe_tagger">5.2.3. Tagger</a>
      </li>
      <li><a href="#run_udpipe_parser">5.2.4. Dependency Parsing</a>
      </li>
      <li><a href="#run_udpipe_output">5.2.5. Output Formats</a>
      </li>
      </ul>
    </li>
    <li><a href="#udpipe_server">5.3. Running the UDPipe REST Server</a>
    </li>
    <li><a href="#model_training">5.4. Training UDPipe Models</a>
      <ul>
      <li><a href="#model_training_reusing_components">5.4.1. Reusing Components from Existing Models</a>
      </li>
      <li><a href="#model_training_random_search">5.4.2. Random Hyperparameter Search</a>
      </li>
      <li><a href="#model_training_tokenizer">5.4.3. Tokenizer</a>
      </li>
      <li><a href="#model_training_tagger">5.4.4. Tagger</a>
      </li>
      <li><a href="#model_training_parser">5.4.5. Parser</a>
      </li>
      <li><a href="#udpipe_accuracy">5.4.6. Measuring Model Accuracy</a>
      </li>
      </ul>
    </li>
    </ul>
  </li>
  <li><a href="#api_reference">UDPipe API Reference</a>
    <ul>
    <li><a href="#versioning">6.1. UDPipe Versioning</a>
    </li>
    <li><a href="#string_piece">6.2. Struct string_piece</a>
    </li>
    <li><a href="#node">6.3. Class word</a>
    </li>
    <li><a href="#multiword_token">6.4. Class multiword_token</a>
    </li>
    <li><a href="#sentence">6.5. Class sentence</a>
    </li>
    <li><a href="#input_format">6.6. Class input_format</a>
    </li>
    <li><a href="#output_format">6.7. Class output_format</a>
    </li>
    <li><a href="#model">6.8. Class model</a>
    </li>
    <li><a href="#pipeline">6.9. Class pipeline</a>
    </li>
    <li><a href="#trainer">6.10. Class trainer</a>
    </li>
    <li><a href="#evaluator">6.11. Class evaluator</a>
    </li>
    <li><a href="#version">6.12. Class version</a>
      <ul>
      <li><a href="#version_current">6.12.1. version::current</a>
      </li>
      </ul>
    </li>
    <li><a href="#cpp_bindings_api">6.13. C++ Bindings API</a>
      <ul>
      <li><a href="#bindings_helper_structures">6.13.1. Helper Structures</a>
      </li>
      <li><a href="#bindings_main_classes">6.13.2. Main Classes</a>
      </li>
      </ul>
    </li>
    <li><a href="#csharp_bindings">6.14. C# Bindings</a>
    </li>
    <li><a href="#java_bindings">6.15. Java Bindings</a>
    </li>
    <li><a href="#perl_bindings">6.16. Perl Bindings</a>
    </li>
    <li><a href="#python_bindings">6.17. Python Bindings</a>
    </li>
    </ul>
  </li>
  <li><a href="#contact">Contact</a>
  </li>
  <li><a href="#udpipe_acknowledgements">Acknowledgements</a>
    <ul>
    <li><a href="#publications">8.1. Publications</a>
    </li>
    <li><a href="#bibtex_for_referencing">8.2. Bibtex for Referencing</a>
    </li>
    <li><a href="#persistent_identifier">8.3. Persistent Identifier</a>
    </li>
    </ul>
  </li>
  </ol>

</div>
<div class="body" ID="body">

<a id="introduction" name="introduction"></a>
<h1>1. Introduction</h1>

<p>
UDPipe is an trainable pipeline for tokenization, tagging, lemmatization and
dependency parsing of CoNLL-U files. UDPipe is language-agnostic and can be trained given
only annotated data in CoNLL-U format. Trained models are provided for
nearly all UD treebanks. UDPipe is available as a binary, as a library for
C++, Python, Perl, Java, C#, and as a web service.
</p>
<p>
UDPipe is a free software under
<a href="http://www.mozilla.org/MPL/2.0/">Mozilla Public License 2.0</a> and the linguistic models
are free for non-commercial use and distributed under
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a> license, although for some
models the original data used to create the model may impose additional
licensing conditions. UDPipe is versioned using <a href="http://semver.org/">Semantic Versioning</a>.
</p>
<p>
Copyright 2016 by Institute of Formal and Applied Linguistics, Faculty of
Mathematics and Physics, Charles University in Prague, Czech Republic.
</p>

<a id="online" name="online"></a>
<h1>2. Online</h1>

<a id="online_demo" name="online_demo"></a>
<h2>2.1. Online Demo</h2>

<p>
<a href="http://lindat.mff.cuni.cz/services/udpipe/">Online demo</a> is available as
one of <a href="http://lindat.mff.cuni.cz/services/">LINDAT/CLARIN services</a>.
</p>

<a id="web_service" name="web_service"></a>
<h2>2.2. Web Service</h2>

<p>
<a href="http://lindat.mff.cuni.cz/services/udpipe/api-reference.php">Web service</a> is also
available as one of <a href="http://lindat.mff.cuni.cz/services/">LINDAT/CLARIN services</a>.
</p>

<a id="release" name="release"></a>
<h1>3. Release</h1>

<a id="download" name="download"></a>
<h2>3.1. Download</h2>

<p>
UDPipe releases are available on <a href="http://github.com/ufal/udpipe">GitHub</a>, either as
a pre-compiled binary package, or source code only. The binary package contains Linux,
Windows and OS X binaries, Java bindings binary, C# bindings binary, and source
code of UDPipe and all language bindings). While the binary
packages do not contain compiled Python or Perl bindings, packages for those
languages are available in standard package repositories, i.e. on PyPI and CPAN.
</p>

<ul>
<li><a href="http://github.com/ufal/udpipe/releases/latest">Latest release</a>
</li>
<li><a href="http://github.com/ufal/udpipe/releases">All releases</a>, <a href="https://github.com/ufal/udpipe/blob/master/CHANGES">Changelog</a>
</li>
</ul>

<a id="language_models" name="language_models"></a>
<h3>3.1.1. Language Models</h3>

<p>
To use UDpipe, a language model is needed. The language models are available
from <a href="http://www.lindat.cz">LINDAT/CLARIN</a> infrastructure and described further
in the
<a href="#users_manual">UDPipe User's Manual</a>.
Currently the following language models are available:
</p>

<ul>
<li>Universal Dependencies 1.2 Models: <a href="http://hdl.handle.net/11234/1-1659">udpipe-ud1.2-160523</a> (<a href="http://ufal.mff.cuni.cz/udpipe/users-manual#universal_dependencies_12_models">documentation</a>)
</li>
</ul>

<a id="license" name="license"></a>
<h2>3.2. License</h2>

<p>
UDPipe is an open-source project and is freely available for non-commercial
purposes. The library is distributed under
<a href="http://www.mozilla.org/MPL/2.0/">Mozilla Public License 2.0</a> and the associated models and data
under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a>, although
for some models the original data used to create the model may impose
additional licensing conditions.
</p>
<p>
If you use this tool for scientific work, please give credit to us by
referencing <a href="#bibtex_for_referencing">Straka et al. 2016</a> and
<a href="http://ufal.mff.cuni.cz/udpipe">UDPipe website</a>.
</p>

<a id="platforms_and_requirements" name="platforms_and_requirements"></a>
<h2>3.3. Platforms and Requirements</h2>

<p>
UDpipe is available as a standalone tool and as a library for Linux/Windows/OS
X. It does not require any additional libraries. As any supervised machine
learning tool, it needs trained linguistic models.
</p>

<a id="instalation" name="instalation"></a>
<h1>4. UDPipe Installation</h1>

<p>
UDPipe releases are available on <a href="http://github.com/ufal/udpipe">GitHub</a>, either as
a pre-compiled binary package, or source code only. The binary package contains Linux,
Windows and OS X binaries, Java bindings binary, C# bindings binary, and source
code of UDPipe and all language bindings. While the binary
packages do not contain compiled Python or Perl bindings, packages for those
languages are available in standard package repositories, i.e. on PyPI and CPAN.
</p>
<p>
To use UDPipe, a language model is needed.
<a href="http://ufal.mff.cuni.cz/udpipe#language_models">Here is a list of available language models</a>.
</p>
<p>
If you want to compile UDPipe manually, sources are available on on
<a href="http://github.com/ufal/udpipe">GitHub</a>, both in the
<a href="http://github.com/ufal/udpipe/releases">pre-compiled binary package releases</a>
and in the repository itself.
</p>

<a id="requirements" name="requirements"></a>
<h2>4.1. Requirements</h2>

<ul>
<li><code>G++ 4.7</code> or newer, <code>clang 3.2</code> or newer, Visual C++ 2015 or newer
</li>
<li><code>make</code>
</li>
<li><code>SWIG 2.0.5</code> or newer for language bindings other than <code>C++</code>
</li>
</ul>

<a id="compilation" name="compilation"></a>
<h2>4.2. Compilation</h2>

<p>
To compile UDPipe, run <code>make</code> in the <code>src</code> directory.
</p>
<p style="margin-bottom:0">
Make targets and options:
</p>
<ul style="margin-top:0">
<li><code>exe</code>: compile the binaries (default)
</li>
<li><code>server</code>: compile the REST server
</li>
<li><code>lib</code>: compile the static library
</li>
<li><code>BITS=32</code> or <code>BITS=64</code>: compile for specified 32-bit or 64-bit architecture instead of the default one
</li>
<li><code>MODE=release</code>: create release build which statically links the C++ runtime and uses LTO
</li>
<li><code>MODE=debug</code>: create debug build
</li>
<li><code>MODE=profile</code>: create profile build
</li>
</ul>

<a id="compilation_platforms" name="compilation_platforms"></a>
<h3>4.2.1. Platforms</h3>

<p style="margin-bottom:0">
Platform can be selected using one of the following options:
</p>
<ul style="margin-top:0">
<li><code>PLATFORM=linux</code>, <code>PLATFORM=linux-gcc</code>: gcc compiler on Linux operating system, default on Linux
</li>
<li><code>PLATFORM=linux-clang</code>: clang compiler on Linux, must be selected manually
</li>
<li><code>PLATFORM=osx</code>, <code>PLATFORM=osx-clang</code>: clang compiler on OS X, default on OS X; <code>BITS=32+64</code> enables multiarch build
</li>
<li><code>PLATFORM=win</code>, <code>PLATFORM=win-gcc</code>: gcc compiler on Windows (TDM-GCC is well tested), default on Windows
</li>
<li><code>PLATFORM=win-vs</code>: Visual C++ 2015 compiler on Windows, must be selected manually; note that the
  <code>cl.exe</code> compiler must be already present in <code>PATH</code> and corresponding <code>BITS=32</code> or <code>BITS=64</code>
  must be specified
</li>
</ul>

<p>
Either POSIX shell or Windows CMD can be used as shell, it is detected automatically.
</p>

<a id="compilation_further_details" name="compilation_further_details"></a>
<h3>4.2.2. Further Details</h3>

<p>
UDPipe uses <a href="http://github.com/ufal/cpp_builtem">C++ BuilTem system</a>,
please refer to its manual if interested in all supported options.
</p>

<a id="other_language_bindings" name="other_language_bindings"></a>
<h2>4.3. Other language bindings</h2>

<a id="csharp_installation" name="csharp_installation"></a>
<h3>4.3.1. C#</h3>

<p>
Binary C# bindings are available in UDPipe binary packages.
</p>
<p>
To compile C# bindings manually, run <code>make</code> in the <code>bindings/csharp</code>
directory, optionally with the options described in UDPipe Installation.
</p>

<a id="java_installation" name="java_installation"></a>
<h3>4.3.2. Java</h3>

<p>
Binary Java bindings are available in UDPipe binary packages.
</p>
<p>
To compile Java bindings manually, run <code>make</code> in the <code>bindings/java</code>
directory, optionally with the options described in UDPipe Installation.
Java 6 and newer is supported.
</p>
<p style="margin-bottom:0">
The Java installation specified in the environment variable <code>JAVA_HOME</code> is
used.  If the environment variable does not exist, the <code>JAVA_HOME</code> can be
specified using
</p>
<pre style="margin-top:0">
make JAVA_HOME=path_to_Java_installation
</pre>

<a id="perl_installation" name="perl_installation"></a>
<h3>4.3.3. Perl</h3>

<p>
The Perl bindings are available as <code>Ufal-UDPipe</code> package on CPAN.
</p>
<p>
To compile Perl bindings manually, run <code>make</code> in the <code>bindings/perl</code>
directory, optionally with the options described in UDPipe Installation.
Perl 5.10 and later is supported.
</p>
<p style="margin-bottom:0">
Path to the include headers of the required Perl version must be specified
in the <code>PERL_INCLUDE</code> variable using
</p>
<pre style="margin-top:0">
make PERL_INCLUDE=path_to_Perl_includes
</pre>

<a id="python_installation" name="python_installation"></a>
<h3>4.3.4. Python</h3>

<p>
The Python bindings are available as <code>ufal.udpipe</code> package on PyPI.
</p>
<p>
To compile Python bindings manually, run <code>make</code> in the <code>bindings/python</code>
directory, optionally with options described in UDPipe Installation. Both
Python 2.6+ and Python 3+ are supported.
</p>
<p style="margin-bottom:0">
Path to the include headers of the required Python version must be specified
in the <code>PYTHON_INCLUDE</code> variable using
</p>
<pre style="margin-top:0">
make PYTHON_INCLUDE=path_to_Python_includes
</pre>

<a id="users_manual" name="users_manual"></a>
<h1>5. UDPipe User's Manual</h1>

<p>
Like any supervised machine learning tool, UDPipe needs a trained linguistic model.
This section describes the available language models and also the commandline
tools and interfaces.
</p>

<a id="universal_dependencies_12_models" name="universal_dependencies_12_models"></a>
<h2>5.1. Universal Dependencies 1.2 Models</h2>

<p>
Universal Dependencies 1.2 Models are distributed under the
<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA</a> licence.
The models are based solely on
<a href="http://hdl.handle.net/11234/1-1548">Universal Dependencies 1.2</a> treebanks.
The models work in UDPipe version 1.0.
</p>
<p>
Universal Dependencies 1.2 Models are versioned according to the date released
in the format <code>YYMMDD</code>, where <code>YY</code>, <code>MM</code> and <code>DD</code> are two-digit
representation of year, month and day, respectively. The latest version is 160523.
</p>

<a id="universal_dependencies_12_models_download" name="universal_dependencies_12_models_download"></a>
<h3>5.1.1. Download</h3>

<p>
The latest version 160523 of the Czech MorphoDiTa models can be downloaded
from <a href="http://hdl.handle.net/11234/1-1659">LINDAT/CLARIN repository</a>.
</p>

<a id="universal_dependencies_12_models_acknowledgements" name="universal_dependencies_12_models_acknowledgements"></a>
<h3>5.1.2. Acknowledgements</h3>

<p>
This work has been partially supported and has been using language resources
and tools developed, stored and distributed by the LINDAT/CLARIN project of the
Ministry of Education, Youth and Sports of the Czech Republic (project <i>LM2015071</i>).
</p>
<p>
The models were trained on <a href="http://hdl.handle.net/11234/1-1548">Universal Dependencies 1.2</a> treebanks.
</p>
<p>
For the UD treebanks which do not contain original plain text version,
raw text is used to train the tokenizer instead. The plain texts
were taken from the <a href="http://hdl.handle.net/11858/00-097C-0000-0022-6133-9">W2C &ndash; Web to Corpus</a>.
</p>

<a id="universal_dependencies_12_models_publications" name="universal_dependencies_12_models_publications"></a>
<h4>5.1.2.1. Publications</h4>

<ul>
<li>(Straka et al. 2016) Straka Milan, Hajič Jan, Straková Jana. <i>UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing.</i> LREC 2016, Portorož, Slovenia, May 2016.
</li>
</ul>

<a id="universal_dependencies_12_models_description" name="universal_dependencies_12_models_description"></a>
<h3>5.1.3. Model Description</h3>

<p>
The Universal Dependencies 1.2 models contain 36 models, each consisting of
a tokenizer, tagger, lemmatizer and dependency parser, all trained using
the UD data. The model for Japanese is missing, because we do not have
the license for the required corpus of Mainichi Shinbun 1995.
</p>
<p>
The tokenizer is trained using the <code>SpaceAfter=No</code> features. If the features
are not present in the data, they can be filled in using raw text in the
language in question (surprisingly, quite little data suffices, we use 500kB).
</p>
<p>
The tagger, lemmatizer and parser are trained using gold UD data.
</p>
<p>
Details about model architecture and training process can be found in the
(Straka et al. 2016) paper.
</p>

<a id="universal_dependencies_12_models_performance" name="universal_dependencies_12_models_performance"></a>
<h3>5.1.4. Model Performance</h3>

<p>
We present the tagger, lemmatizer and parser performance, measured
on the testing portion of the data. Only the segmentation and the
tokenization of the testing data is retained before evaluation.
Therefore, the dependency parser is evaluated without gold POS tags.
</p>

<table border="1">
<tr>
<th>Treebank</th>
<th>UPOS</th>
<th>XPOS</th>
<th>Feats</th>
<th>All Tags</th>
<th>Lemma</th>
<th>UAS</th>
<th>LAS</th>
</tr>
<tr>
<td>Ancient Greek</td>
<td align="right">91.1%</td>
<td align="right">77.8%</td>
<td align="right">88.7%</td>
<td align="right">77.7%</td>
<td align="right">86.9%</td>
<td align="right">68.1%</td>
<td align="right">61.6%</td>
</tr>
<tr>
<td>Ancient Greek-PROIEL</td>
<td align="right">96.7%</td>
<td align="right">96.4%</td>
<td align="right">89.3%</td>
<td align="right">88.4%</td>
<td align="right">93.4%</td>
<td align="right">75.8%</td>
<td align="right">69.6%</td>
</tr>
<tr>
<td>Arabic</td>
<td align="right">98.8%</td>
<td align="right">97.7%</td>
<td align="right">97.8%</td>
<td align="right">97.6%</td>
<td align="center">-</td>
<td align="right">80.4%</td>
<td align="right">75.6%</td>
</tr>
<tr>
<td>Basque</td>
<td align="right">93.3%</td>
<td align="center">-</td>
<td align="right">87.2%</td>
<td align="right">85.4%</td>
<td align="right">93.5%</td>
<td align="right">74.8%</td>
<td align="right">69.5%</td>
</tr>
<tr>
<td>Bulgarian</td>
<td align="right">97.8%</td>
<td align="right">94.8%</td>
<td align="right">94.4%</td>
<td align="right">93.1%</td>
<td align="right">94.6%</td>
<td align="right">89.0%</td>
<td align="right">84.2%</td>
</tr>
<tr>
<td>Croatian</td>
<td align="right">94.9%</td>
<td align="center">-</td>
<td align="right">85.5%</td>
<td align="right">85.0%</td>
<td align="right">93.1%</td>
<td align="right">78.6%</td>
<td align="right">71.0%</td>
</tr>
<tr>
<td>Czech</td>
<td align="right">98.4%</td>
<td align="right">93.2%</td>
<td align="right">92.6%</td>
<td align="right">92.2%</td>
<td align="right">97.8%</td>
<td align="right">86.9%</td>
<td align="right">83.0%</td>
</tr>
<tr>
<td>Danish</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="right">94.8%</td>
<td align="right">93.6%</td>
<td align="right">95.2%</td>
<td align="right">78.6%</td>
<td align="right">74.8%</td>
</tr>
<tr>
<td>Dutch</td>
<td align="right">89.7%</td>
<td align="right">88.7%</td>
<td align="right">91.2%</td>
<td align="right">86.4%</td>
<td align="right">88.9%</td>
<td align="right">78.1%</td>
<td align="right">70.7%</td>
</tr>
<tr>
<td>English</td>
<td align="right">94.5%</td>
<td align="right">93.8%</td>
<td align="right">95.4%</td>
<td align="right">92.5%</td>
<td align="right">97.0%</td>
<td align="right">84.2%</td>
<td align="right">80.6%</td>
</tr>
<tr>
<td>Estonian</td>
<td align="right">88.0%</td>
<td align="right">73.7%</td>
<td align="right">80.0%</td>
<td align="right">73.6%</td>
<td align="right">77.0%</td>
<td align="right">79.9%</td>
<td align="right">71.5%</td>
</tr>
<tr>
<td>Finnish</td>
<td align="right">94.9%</td>
<td align="right">96.0%</td>
<td align="right">93.2%</td>
<td align="right">92.1%</td>
<td align="right">86.8%</td>
<td align="right">81.0%</td>
<td align="right">76.5%</td>
</tr>
<tr>
<td>Finnish-FTB</td>
<td align="right">94.0%</td>
<td align="right">91.6%</td>
<td align="right">93.3%</td>
<td align="right">91.2%</td>
<td align="right">89.1%</td>
<td align="right">81.5%</td>
<td align="right">76.9%</td>
</tr>
<tr>
<td>French</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">95.8%</td>
<td align="center">-</td>
<td align="right">82.8%</td>
<td align="right">78.4%</td>
</tr>
<tr>
<td>German</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="right">78.2%</td>
<td align="right">72.2%</td>
</tr>
<tr>
<td>Gothic</td>
<td align="right">95.5%</td>
<td align="right">95.7%</td>
<td align="right">88.0%</td>
<td align="right">86.3%</td>
<td align="right">93.4%</td>
<td align="right">76.4%</td>
<td align="right">68.2%</td>
</tr>
<tr>
<td>Greek</td>
<td align="right">97.3%</td>
<td align="right">97.3%</td>
<td align="right">92.8%</td>
<td align="right">91.7%</td>
<td align="right">94.8%</td>
<td align="right">80.3%</td>
<td align="right">76.5%</td>
</tr>
<tr>
<td>Hebrew</td>
<td align="right">94.9%</td>
<td align="right">94.9%</td>
<td align="right">91.3%</td>
<td align="right">90.5%</td>
<td align="center">-</td>
<td align="right">82.6%</td>
<td align="right">76.8%</td>
</tr>
<tr>
<td>Hindi</td>
<td align="right">95.8%</td>
<td align="right">94.8%</td>
<td align="right">90.2%</td>
<td align="right">87.7%</td>
<td align="right">98.0%</td>
<td align="right">91.7%</td>
<td align="right">87.5%</td>
</tr>
<tr>
<td>Hungarian</td>
<td align="right">92.6%</td>
<td align="center">-</td>
<td align="right">89.9%</td>
<td align="right">88.9%</td>
<td align="right">86.9%</td>
<td align="right">77.0%</td>
<td align="right">70.6%</td>
</tr>
<tr>
<td>Indonesian</td>
<td align="right">93.5%</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="right">93.5%</td>
<td align="center">-</td>
<td align="right">79.9%</td>
<td align="right">73.3%</td>
</tr>
<tr>
<td>Irish</td>
<td align="right">91.8%</td>
<td align="right">90.3%</td>
<td align="right">79.4%</td>
<td align="right">76.6%</td>
<td align="right">87.3%</td>
<td align="right">74.4%</td>
<td align="right">66.1%</td>
</tr>
<tr>
<td>Italian</td>
<td align="right">97.2%</td>
<td align="right">97.0%</td>
<td align="right">97.1%</td>
<td align="right">96.2%</td>
<td align="right">97.7%</td>
<td align="right">88.6%</td>
<td align="right">85.8%</td>
</tr>
<tr>
<td>Latin</td>
<td align="right">91.2%</td>
<td align="right">75.8%</td>
<td align="right">79.3%</td>
<td align="right">75.6%</td>
<td align="right">79.9%</td>
<td align="right">57.1%</td>
<td align="right">46.7%</td>
</tr>
<tr>
<td>Latin-ITT</td>
<td align="right">98.8%</td>
<td align="right">94.0%</td>
<td align="right">94.6%</td>
<td align="right">93.8%</td>
<td align="right">98.3%</td>
<td align="right">79.9%</td>
<td align="right">76.4%</td>
</tr>
<tr>
<td>Latin-PROIEL</td>
<td align="right">96.4%</td>
<td align="right">96.0%</td>
<td align="right">88.9%</td>
<td align="right">88.2%</td>
<td align="right">95.3%</td>
<td align="right">75.3%</td>
<td align="right">68.3%</td>
</tr>
<tr>
<td>Norwegian</td>
<td align="right">97.2%</td>
<td align="center">-</td>
<td align="right">95.5%</td>
<td align="right">94.7%</td>
<td align="right">96.9%</td>
<td align="right">86.7%</td>
<td align="right">84.1%</td>
</tr>
<tr>
<td>Old Church Slavonic</td>
<td align="right">95.3%</td>
<td align="right">95.1%</td>
<td align="right">89.1%</td>
<td align="right">88.2%</td>
<td align="right">92.9%</td>
<td align="right">80.6%</td>
<td align="right">73.4%</td>
</tr>
<tr>
<td>Persian</td>
<td align="right">97.0%</td>
<td align="right">96.3%</td>
<td align="right">96.5%</td>
<td align="right">96.2%</td>
<td align="center">-</td>
<td align="right">83.8%</td>
<td align="right">79.4%</td>
</tr>
<tr>
<td>Polish</td>
<td align="right">95.8%</td>
<td align="right">84.0%</td>
<td align="right">84.1%</td>
<td align="right">83.8%</td>
<td align="right">92.8%</td>
<td align="right">86.3%</td>
<td align="right">79.6%</td>
</tr>
<tr>
<td>Portuguese</td>
<td align="right">97.6%</td>
<td align="right">92.3%</td>
<td align="right">95.3%</td>
<td align="right">92.0%</td>
<td align="right">97.8%</td>
<td align="right">85.8%</td>
<td align="right">81.9%</td>
</tr>
<tr>
<td>Romanian</td>
<td align="right">89.0%</td>
<td align="right">81.0%</td>
<td align="right">82.3%</td>
<td align="right">81.0%</td>
<td align="right">75.3%</td>
<td align="right">68.6%</td>
<td align="right">56.9%</td>
</tr>
<tr>
<td>Slovenian</td>
<td align="right">95.7%</td>
<td align="right">88.2%</td>
<td align="right">88.6%</td>
<td align="right">87.5%</td>
<td align="right">95.0%</td>
<td align="right">84.1%</td>
<td align="right">80.3%</td>
</tr>
<tr>
<td>Spanish</td>
<td align="right">95.3%</td>
<td align="center">-</td>
<td align="right">95.9%</td>
<td align="right">93.4%</td>
<td align="right">96.3%</td>
<td align="right">84.2%</td>
<td align="right">80.3%</td>
</tr>
<tr>
<td>Swedish</td>
<td align="right">95.8%</td>
<td align="right">93.9%</td>
<td align="right">94.8%</td>
<td align="right">93.2%</td>
<td align="right">95.5%</td>
<td align="right">81.4%</td>
<td align="right">77.1%</td>
</tr>
<tr>
<td>Tamil</td>
<td align="right">85.9%</td>
<td align="right">80.8%</td>
<td align="right">84.3%</td>
<td align="right">80.2%</td>
<td align="right">88.0%</td>
<td align="right">67.2%</td>
<td align="right">58.8%</td>
</tr>
</table>

<a id="run_udpipe" name="run_udpipe"></a>
<h2>5.2. Running UDPipe</h2>

<p style="margin-bottom:0">
Probably the most common usage of UDPipe is to tokenize, tag and parse input using
</p>
<pre style="margin-top:0">
udpipe --tokenize --tag --parse udpipe_model
</pre>

<p>
The input is assumed to be in UTF-8 encoding and can be either already tokenized
and segmented, or it can be a plain text which is tokenized and segmented automatically.
</p>
<p>
Any number of files can be specified after the <code>udpipe_model</code> and if no
file is given, input is read from standard input. The output is by default
saved to standard output, but if <code>--outfile=name</code> is used, it is saved
to the given file name. The output file name can contain a <code>{}</code>, which is
replaced by a base name of the processed file (i.e., without directories
and an extension).
</p>
<p style="margin-bottom:0">
The full command syntax of running UDPipe is
</p>
<pre style="margin-top:0">
udpipe [options] udpipe_model file ...
Options: --input=[conllu|horizontal|vertical]
         --outfile=output file template
         --output=[conllu|horizontal|vertical]
         --tokenize (perform tokenization)
         --tokenizer=tokenizer options, implies --tokenize
         --tag (perform tagging)
         --tagger=tagger options, implies --tag
         --parse (perform parsing)
         --parser=parser options, implies --parse
</pre>

<a id="run_udpipe_tokenizer" name="run_udpipe_tokenizer"></a>
<h3>5.2.1. Tokenizer</h3>

<p>
If the <code>--tokenize</code> input is supplied, the input is assumed to be
plain text and is tokenized using model tokenizer. Additional arguments to the
tokenizer might be specified using <code>--tokenizer=data</code> option (which implies
<code>--tokenize</code>).
</p>

<a id="run_udpipe_input" name="run_udpipe_input"></a>
<h3>5.2.2. Input Formats</h3>

<p style="margin-bottom:0">
If the tokenizer is not used, the input format is specified using the
<code>--input</code> option. Currently supported input formats are:
</p>
<ul style="margin-top:0">
<li><code>conllu</code> (default): the <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
</li>
<li><code>horizontal</code>: each sentence on a separate line, with tokens separated by spaces
</li>
<li><code>vertical</code>: each token on a separate line, with an empty line denoting end of sentence;
  only the first space-separated word is used as a token, the rest of the line is ignored
</li>
</ul>

<a id="run_udpipe_tagger" name="run_udpipe_tagger"></a>
<h3>5.2.3. Tagger</h3>

<p>
If the <code>--tag</code> input is supplied, the input is POS tagged lemmatized
using the model tagger. Additional arguments to the tagger might be
specified using <code>--tagger=data</code> option (which implies <code>--tag</code>).
</p>

<a id="run_udpipe_parser" name="run_udpipe_parser"></a>
<h3>5.2.4. Dependency Parsing</h3>

<p>
If the <code>--parse</code> input is supplied, the input is parsed using
the model dependency parser.  Additional arguments to the parser might be
specified using <code>--parser=data</code> option (which implies <code>--parse</code>).
</p>

<a id="run_udpipe_output" name="run_udpipe_output"></a>
<h3>5.2.5. Output Formats</h3>

<p style="margin-bottom:0">
The output format is specified using the <code>--output</code> option. Currently
supported output formats are:
</p>
<ul style="margin-top:0">
<li><code>conllu</code> (default): the <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
</li>
<li><code>horizontal</code>: each sentence on a separate line, with words separated by a single space
</li>
<li><code>vertical</code>: each word on a separate line, with an empty line denoting end of sentence
</li>
</ul>

<a id="udpipe_server" name="udpipe_server"></a>
<h2>5.3. Running the UDPipe REST Server</h2>

<p>
UDPipe also provides REST server binary <code>udpipe_server</code>.
The binary uses <a href="http://github.com/ufal/microrestd">MicroRestD</a> as a REST
server implementation and provides
<a href="http://lindat.mff.cuni.cz/services/udpipe/api-reference.php">UDPipe REST API</a>.
</p>
<p style="margin-bottom:0">
The full command syntax of <code>udpipe_server</code> is
</p>
<pre style="margin-top:0">
udpipe_server [options] port (rest_id model_file acknowledgements)*
Options: --daemon
</pre>

<p>
The <code>udpipe_server</code> can run either in foreground or in background (when
<code>--daemon</code> is used). The specified model files are loaded during start and
kept in memory all the time. This behaviour may change in future to load the
models on demand.
</p>

<a id="model_training" name="model_training"></a>
<h2>5.4. Training UDPipe Models</h2>

<p style="margin-bottom:0">
Custom UDPipe models can be trained using the following syntax:
</p>
<pre style="margin-top:0">
udpipe --train model.output [--heldout=heldout_data] training_file ...
</pre>

<p>
The training data should be in <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>.
</p>
<p>
By default three model components are trained &ndash; a tokenizer, tagger and
a parser.  Any subset of the model components can be trained and a model
component may be copied from an existing model.
</p>
<p>
The training options are specified for each model component separately
using the <code>--tokenizer</code>, <code>--tagger</code> and <code>--parser</code> option.
If a model component should not be trained, value <code>none</code> should
be used (e.g., <code>--tagger=none</code>).
</p>
<p>
The options are <code>name=value</code> pairs separated by a semicolon. The
value can be either a simple string value (ending by a semicolon),
file content specified as <code>name=file:filename</code>, or an arbitrary
string value specified as <code>name=data:length:value</code>, where the value
is exactly <code>length</code> bytes long.
</p>

<a id="model_training_reusing_components" name="model_training_reusing_components"></a>
<h3>5.4.1. Reusing Components from Existing Models</h3>

<p>
The model components (tagger, parser or tagger) can be reused from
existing models, by specifying <code>from_model=file:filename</code> option.
</p>

<a id="model_training_random_search" name="model_training_random_search"></a>
<h3>5.4.2. Random Hyperparameter Search</h3>

<p>
The default values of hyperparameters is set to the values
which were used the most during UD 1.2 models training, but if you
want to reach best performance, the hyperparameters must be tuned.
</p>
<p>
Apart from manual grid search, UDPipe can perform a simple random search.
You can perform the random search by repeatedly training UDPipe
(preferably in parallel, most likely on different computers)
while specifying different training run number &ndash; some of the
hyperparameters (chosen by us; but if you specify their value
on command line, it is not modified) change their value on different
training runs. The pseudorandom sequences of hyperparameters
are of course deterministic.
</p>
<p>
The training run can be specified by providing <code>run=number</code> option
to a model component. The run number 1 is the default one (with best
hyperparameters for the UD 1.2 models), runs 2 and more randomize
the hyperparameters.
</p>

<a id="model_training_tokenizer" name="model_training_tokenizer"></a>
<h3>5.4.3. Tokenizer</h3>

<p>
The tokenizer is trained using the <code>SpaceAfter=No</code> features in the CoNLL-U files.
If the feature is not present, a <i>detokenizer</i> can be used to guess
the <code>SpaceAfter=No</code> features according to a supplied plain text.
</p>
<p>
In order to use the detokenizer, use <code>detokenizer=file:filename_with_plaintext</code>
option. In UD 1.2 models, optimal performance is achieved with very small plain
texts &ndash; only 500kB.
</p>
<p style="margin-bottom:0">
The tokenizer recognizes the following options:
</p>
<ul style="margin-top:0">
<li><code>tokenize_url</code> (default <code>true</code>): tokenize URLs and emails using a manually
    implemented recognizer
</li>
<li><code>epochs</code> (default 100): the number of epochs to train the tokenizer for
</li>
<li><code>batch_size</code> (default 50): batch size used during tokenizer training
</li>
<li><code>learning_rate</code> (default 0.005): the learning rate used during tokenizer training
</li>
<li><code>dropout</code> (default 0.1): dropout used during tokenizer training
</li>
</ul>

<p>
During random hyperparameter search, <code>batch_size</code> is chosen uniformly from <i>{50,100}</i>
and <code>learning_rate</code> logarithmically from <i>&lt;0.0005, 0.01)</i>.
</p>

<a id="model_training_tagger" name="model_training_tagger"></a>
<h3>5.4.4. Tagger</h3>

<p>
The tagging is currently performed using <a href="http://ufal.mff.cuni.cz/morphodita">MorphoDiTa</a>.
The UDPipe tagger consists of possibly several MorphoDiTa models, each tagging
some of the POS tags and/or lemmas.
</p>
<p>
By default, only one model is constructed, which generates all available tags (UPOS,
XPOS, Feats and Lemma). However, we found out during the UD 1.2 models training
that performance improves if one model tags the UPOS, XPOS and Feats tags, while the
other is performing lemmatization. Therefore, if you utilize two MorphoDiTa models,
by default the first one generates all tags and the second one performs lemmatization.
</p>
<p>
The number of MorphoDiTa models can be specified using <code>models=number</code> parameter.
All other parameters may be either generic for all models (<code>guesser_suffix_rules=5</code>),
or specific for a given model (<code>guesser_suffix_rules_2=6</code>), including the
<code>from_model</code> option (therefore, MorphoDiTa models can be trained separately
and then combined together to one UDPipe model).
</p>
<p>
Every model utilizes UPOS for disambiguation and the first model is the one producing
the UPOS tags on output.
</p>
<p style="margin-bottom:0">
The tokenizer recognizes the following options:
</p>
<ul style="margin-top:0">
<li><code>use_lemma</code> (default for the second model and also if there is only one model): use the
  lemma field internally to perform disambiguation; the lemma may be not outputted
</li>
<li><code>provide_lemma</code> (default for the second model and also if there is only one model):
  produce the disambiguated lemma on output
</li>
<li><code>use_xpostag</code> (default for the first model): use the
  XPOS tags internally to perform disambiguation; it may not be outputted
</li>
<li><code>provide_xpostag</code> (default for the first model): produce the disambiguated XPOS tag on output
</li>
<li><code>use_feats</code> (default for the first model): use the
  Feats internally to perform disambiguation; it may not be outputted
</li>
<li><code>provide_feats</code> (default for the first model): produce the disambiguated Feats field on output
</li>
<li><code>guesser_suffix_rules</code> (default 8): number of rules generated for every suffix
</li>
<li><code>guesser_enrich_dictionary</code> (default 6): number of rules generated for forms present
  in training data (assuming that the analyses from the training data may not be all)
</li>
</ul>

<p>
During random hyperparameter search, <code>guesser_suffix_rules</code> is chosen uniformly from
<i>{5,6,7,8,9,10,11,12}</i> and <code>guesser_enrich_dictionary</code> is chosen uniformly from
<i>{3,4,5,6,7,8,9,10}</i>.
</p>
<p>
Note that for very large input training files it may happen that the
morphological dictionary will be too large and the training will end with an error.
If that happens, use smaller values for <code>guesser_suffix_rules</code> and/or <code>guesser_enrich_dictionary</code>.
</p>

<a id="model_training_parser" name="model_training_parser"></a>
<h3>5.4.5. Parser</h3>

<p>
The parsing is performed using <a href="http://ufal.mff.cuni.cz/parsito">Parsito</a>, which is a
transition-based parser using neural network classifier.
</p>
<p style="margin-bottom:0">
The transition-based systems can be configured by the following options:
</p>
<ul style="margin-top:0">
<li><code>transition_system</code> (default projective): which transition system to use for parsing (language dependant, you can choose according
  to language properties or try all and choose the best)
  <ul>
  <li><code>projective</code>: projective stack-based arc standard system with <code>shift</code>, <code>left_arc</code> and <code>right_arc</code> transitions
  </li>
  <li><code>swap</code>: fully non-projective system which extends <code>projective</code> system by adding <code>swap</code> transition
  </li>
  <li><code>link2</code>: partially non-projective system which extends <code>projective</code> system by adding <code>left_arc2</code> and <code>right_arc2</code> transitions
  </li>
  </ul>
</li>
<li><code>transition_oracle</code> (default dynamic/static_lazy_static whichever first is applicable): which transition oracle to use for the chosen <code>transition_system</code>:
  <ul>
  <li><code>transition_system=projective</code>: available oracles are <code>static</code> and <code>dynamic</code> (<code>dynamic</code> usually gives better results, but training time is slower)
  </li>
  <li><code>transition_system=swap</code>: available oracles are <code>static_eager</code> and <code>static_lazy</code> (<code>static_lazy</code> almost always gives better results)
  </li>
  <li><code>transition_system=link2</code>: only available oracle is <code>static</code>
  </li>
  </ul>
</li>
<li><code>structured_interval</code> (default 8): use search-based oracle in addition to the <code>translation_oracle</code> specified. This almost always gives better results, but makes training 2-3 times slower. For details, see the paper <i>Straka et al. 2015: Parsing Universal Dependency Treebanks using Neural Networks and Search-Based Oracle</i>
</li>
</ul>

<p style="margin-bottom:0">
The embeddings used by the parser can be specified as follows:
</p>
<ul style="margin-top:0">
<li><code>embedding_upostag</code> (default 20): the dimension of the UPos embedding used in the parser
</li>
<li><code>embedding_feats</code> (default 20): the dimension of the Feats embedding used in the parser
</li>
<li><code>embedding_xpostag</code> (default 0): the dimension of the XPos embedding used in the parser
</li>
<li><code>embedding_form</code> (default 50): the dimension of the Form embedding used in the parser
</li>
<li><code>embedding_lemma</code> (default 0): the dimension of the Lemma embedding used in the parser
</li>
<li><code>embedding_form_file</code>: pre-trained word embeddings created by <code>word2vec</code> can be optionally used;
    pretraining embeddings even on the UD data itself improves accuracy (we use <code>-cbow 0 -size 50 -window 10 -negative 5 -hs 0 -sample 1e-1 -threads 12 -binary 0 -iter 15 -min-count 2</code> options to pretrain on UD data)
</li>
<li><code>embedding_lemma_file</code>: pre-trained lemma embeddings created by <code>word2vec</code> can be optionally used;
</li>
</ul>

<p>
Note that form embedding could be pretrained directly in UDPipe (and will probably be pretrained
in future UDPipe version).
</p>
<p style="margin-bottom:0">
The neural network training options:
</p>
<ul style="margin-top:0">
<li><code>iterations</code> (default 10): number of training iterations to use
</li>
<li><code>hidden_layer</code> (default 200): the size of the hidden layer
</li>
<li><code>batch_size</code> (default 10): batch size used during neural network training
</li>
<li><code>learning_rate</code> (default 0.02): the learning rate used during neural network training
</li>
<li><code>learning_rate_final</code> (0.001): the final learning rate used during neural network training
</li>
<li><code>l2</code> (0.5): the L2 regularization used during neural network training
</li>
</ul>

<p>
During random hyperparameter search, <code>structured_interval</code> is chosen uniformly from
<i>{0,8,10}</i>, <code>learning_rate</code> is chosen logarithmically from <code>&lt;0.005,0.04)</code> and
<code>l2</code> is chosen uniformly from <code>&lt;0.2,0.6)</code>.
</p>

<a id="udpipe_accuracy" name="udpipe_accuracy"></a>
<h3>5.4.6. Measuring Model Accuracy</h3>

<p style="margin-bottom:0">
Measuring custom model accuracy can be performed by running:
</p>
<pre style="margin-top:0">
udpipe --accuracy [udpipe_options] udpipe_model file ...
</pre>

<p>
The command syntax is similar to the regular UDPipe operation, only
the input must be always in <a href="http://universaldependencies.org/docs/format.html">CoNLL-U format</a>
and the <code>--input</code> and <code>--output</code> options are ignored.
</p>
<p>
If <code>--tokenize(r)</code> option is passed, tokenizer performance is evaluted
(using <code>SpaceAfter=No</code> features of the input file). If <code>--tag(ger)</code> and/or <code>--parse(r)</code>
options are passed, tagger and/or dependency parser performance is evaluated, respectively.
</p>

<a id="api_reference" name="api_reference"></a>
<h1>6. UDPipe API Reference</h1>

<p>
The UDPipe API is defined in header <code>udpipe.h</code> and resides in
<code>ufal::udpipe</code> namespace. The API allows only using existing models,
for custom model creation you have to use the <code>train_parser</code> binary.
</p>
<p>
The strings used in the UDPipe API are always UTF-8 encoded (except from
file paths, whose encoding is system dependent).
</p>

<a id="versioning" name="versioning"></a>
<h2>6.1. UDPipe Versioning</h2>

<p>
UDPipe is versioned using <a href="http://semver.org/">Semantic Versioning</a>.
Therefore, a version consists of three numbers <i>major.minor.patch</i>, optionally
followed by a hyphen and pre-release version info, with the following semantics:
</p>

<ul>
<li>Stable versions have no pre-release version info, development have non-empty
  pre-release version info.
</li>
<li>Two versions with the same <i>major.minor</i> have the same API with the same
  behaviour, apart from bugs. Therefore, if only <i>patch</i> is increased, the
  new version is only a bug-fix release.
</li>
<li>If two versions <i>v</i> and <i>u</i> have the same <i>major</i>, but <i>minor(v)</i> is
  greater than <i>minor(u)</i>, version <i>v</i> contains only additions to the API.
  In other words, the API of <i>u</i> is all present in <i>v</i> with the same
  behaviour (once again apart from bugs). It is therefore safe to upgrade to
  a newer UDPipe version with the same <i>major</i>.
</li>
<li>If two versions differ in <i>major</i>, their API may differ in any way.
</li>
</ul>

<p>
Models created by UDPipe have the same behaviour in all UDPipe
versions with same <i>major</i>, apart from obvious bugfixes. On the other hand,
models created from the same data by different <i>major.minor</i> UDPipe
versions may have different behaviour.
</p>

<a id="string_piece" name="string_piece"></a>
<h2>6.2. Struct string_piece</h2>

<pre>
struct string_piece {
  const char* str;
  size_t len;

  string_piece();
  string_piece(const char* str);
  string_piece(const char* str, size_t len);
  string_piece(const std::string&amp; str);
}
</pre>

<p>
The <a href="#string_piece"><code>string_piece</code></a> is used for efficient string passing. The string
referenced in <a href="#string_piece"><code>string_piece</code></a> is not owned by it, so users have to make sure
the referenced string exists as long as the <a href="#string_piece"><code>string_piece</code></a>.
</p>

<a id="node" name="node"></a>
<h2>6.3. Class word</h2>

<pre>
class word {
 public:
  int id;         // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  string form;    // form
  string lemma;   // lemma
  string upostag; // universal part-of-speech tag
  string xpostag; // language-specific part-of-speech tag
  string feats;   // list of morphological features
  int head;       // head, 0 is root, &lt;0 is undefined
  string deprel;  // dependency relation to the head
  string deps;    // secondary dependencies
  string misc;    // miscellaneous information

  vector&lt;int&gt; children;

  word(int id = -1, string_piece form = string_piece());
};
</pre>

<p>
The <a href="#word"><code>word</code></a> class represents a sentence word.
The <a href="#word"><code>word</code></a> fields correspond to <a href="http://universaldependencies.org/docs/format.html">CoNLL-U fields</a>,
with the <code>children</code> field representing the opposite direction of <code>head</code> links.
</p>

<a id="multiword_token" name="multiword_token"></a>
<h2>6.4. Class multiword_token</h2>

<pre>
class multiword_token {
 public:
  int id_first, id_last;
  string form;
  string misc;

  multiword_token(int id_first = -1, int id_last = -1, string_piece form = string_piece(), string_piece misc = string_piece());
};
</pre>

<a id="sentence" name="sentence"></a>
<h2>6.5. Class sentence</h2>

<pre>
class sentence {
 public:
  sentence();

  vector&lt;word&gt; words;
  vector&lt;multiword_token&gt; multiword_tokens;
  vector&lt;string&gt; comments;
  static const string root_form;

  bool empty();
  void clear();
  word&amp; add_word(string_piece form = string_piece());
  void set_head(int id, int head, const string&amp; deprel);
  void unlink_all_words();
};
</pre>

<a id="input_format" name="input_format"></a>
<h2>6.6. Class input_format</h2>

<pre>
class input_format {
 public:
  virtual ~input_format() {}

  virtual bool read_block(istream&amp; is, string&amp; block) const = 0;
  virtual void set_text(string_piece text, bool make_copy = false) = 0;
  virtual bool next_sentence(sentence&amp; s, string&amp; error) = 0;

  // Static factory methods
  static input_format* new_input_format(const string&amp; name);
  static input_format* new_conllu_input_format();
  static input_format* new_horizontal_input_format();
  static input_format* new_vertical_input_format();
};
</pre>

<a id="output_format" name="output_format"></a>
<h2>6.7. Class output_format</h2>

<pre>
class output_format {
 public:
  virtual ~output_format() {}

  virtual void write_sentence(const sentence&amp; s, ostream&amp; os) const = 0;

  // Static factory methods
  static output_format* new_output_format(const string&amp; name);
  static output_format* new_conllu_output_format();
  static output_format* new_horizontal_output_format();
  static output_format* new_vertical_output_format();
};
</pre>

<a id="model" name="model"></a>
<h2>6.8. Class model</h2>

<pre>
class model {
 public:
  virtual ~model() {}

  static model* load(const char* fname);
  static model* load(istream&amp; is);

  virtual input_format* new_tokenizer(const string&amp; options) const = 0;
  virtual bool tag(sentence&amp; s, const string&amp; options, string&amp; error) const = 0;
  virtual bool parse(sentence&amp; s, const string&amp; options, string&amp; error) const = 0;

  static const string DEFAULT;
};
</pre>

<a id="pipeline" name="pipeline"></a>
<h2>6.9. Class pipeline</h2>

<pre>
class pipeline {
 public:
  pipeline(const model* m, const string&amp; input, const string&amp; tagger, const string&amp; parser, const string&amp; output);

  void set_model(const model* m);
  void set_input(const string&amp; input);
  void set_tagger(const string&amp; tagger);
  void set_parser(const string&amp; parser);
  void set_output(const string&amp; output);

  bool process(istream&amp; is, ostream&amp; os, string&amp; error) const;

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="trainer" name="trainer"></a>
<h2>6.10. Class trainer</h2>

<pre>
class trainer {
 public:
  static bool train(const string&amp; method, const vector&lt;sentence&gt;&amp; train, const vector&lt;sentence&gt;&amp; heldout,
                    const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser,
                    ostream&amp; os, string&amp; error);

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="evaluator" name="evaluator"></a>
<h2>6.11. Class evaluator</h2>

<pre>
class evaluator {
 public:
  evaluator(const model* m, const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser);

  void set_model(const model* m);
  void set_tokenizer(const string&amp; tokenizer);
  void set_tagger(const string&amp; tagger);
  void set_parser(const string&amp; parser);

  bool evaluate(istream&amp; is, ostream&amp; os, string&amp; error) const;

  static const string DEFAULT;
  static const string NONE;
};
</pre>

<a id="version" name="version"></a>
<h2>6.12. Class version</h2>

<pre>
class version {
 public:
  unsigned major;
  unsigned minor;
  unsigned patch;
  string prerelease;

  static <A HREF="#version">version</A> <A HREF="#version_current">current</A>();
};
</pre>

<p>
The <a href="#version"><code>version</code></a> class represents UDPipe version.
See <a href="#versioning">UDPipe Versioning</a> for more information.
</p>

<a id="version_current" name="version_current"></a>
<h3>6.12.1. version::current</h3>

<pre>
static <A HREF="#version">version</A> current();
</pre>

<p>
Returns current UDPipe version.
</p>

<a id="cpp_bindings_api" name="cpp_bindings_api"></a>
<h2>6.13. C++ Bindings API</h2>

<p>
Bindings for other languages than C++ are created using SWIG from the C++
bindings API, which is a slightly modified version of the native C++ API.
Main changes are replacement of <a href="#string_piece"><code>string_piece</code></a> type by native
strings and removal of methods using <code>istream</code>. Here is the C++ bindings API
declaration:
</p>

<a id="bindings_helper_structures" name="bindings_helper_structures"></a>
<h3>6.13.1. Helper Structures</h3>

<pre>
typedef vector&lt;int&gt; Children;

typedef vector&lt;string&gt; Comments;

class ProcessingError {
public:
  bool occurred();
  string message;
};

class Word {
 public:
  int id;         // 0 is root, &gt;0 is sentence word, &lt;0 is undefined
  string form;    // form
  string lemma;   // lemma
  string upostag; // universal part-of-speech tag
  string xpostag; // language-specific part-of-speech tag
  string feats;   // list of morphological features
  int head;       // head, 0 is root, &lt;0 is undefined
  string deprel;  // dependency relation to the head
  string deps;    // secondary dependencies
  string misc;    // miscellaneous information

  Children children;

  Word(int id = -1, const string&amp; form = string());
};
typedef vector&lt;Word&gt; Words;

class MultiwordToken {
 public:
  int idFirst, idLast;
  string form;
  string misc;

  MultiwordToken(int id_first = -1, int id_last = -1, const string&amp; form = string(), const string&amp; misc = string());
};
typedef vector&lt;MultiwordToken&gt; MultiwordTokens;

class Sentence {
 public:
  Sentence();

  Words words;
  MultiwordTokens multiwordTokens;
  Comments comments
  static const string rootForm;

  bool empty();
  void clear();
  virtual Word&amp; addWord(const char* form);
  void setHead(int id, int head, const string&amp; deprel);
  void unlinkAllWords();
};
typedef vector&lt;Sentence&gt; Sentences;
</pre>

<a id="bindings_main_classes" name="bindings_main_classes"></a>
<h3>6.13.2. Main Classes</h3>

<pre>
class InputFormat {
 public:
  virtual void setText(const char* text);
  virtual bool nextSentence(Sentence&amp; s, ProcessingError* error = nullptr);

  static InputFormat* newInputFormat(const string&amp; name);
  static InputFormat* newConlluInputFormat();
  static InputFormat* newHorizontalInputFormat();
  static InputFormat* newVerticalInputFormat();
};

class OutputFormat {
 public:
  virtual string writeSentence(const Sentence&amp; s) const;

  static OutputFormat* newOutputFormat(const string&amp; name);
  static OutputFormat* newConlluOutputFormat();
  static OutputFormat* newHorizontalOutputFormat();
  static OutputFormat* newVerticalOutputFormat();
};

class Model {
 public:
  static Model* load(const char* fname);

  virtual InputFormat* newTokenizer(const string&amp; options) const;
  virtual bool tag(Sentence&amp; s, const string&amp; options, ProcessingError* error = nullptr) const;
  virtual bool parse(Sentence&amp; s, const string&amp; options, ProcessingError* error) const;

  static const string DEFAULT;
};

class Pipeline {
 public:
  Pipeline(const Model* m, const string&amp; input, const string&amp; tagger, const string&amp; parser, const string&amp; output);

  void setModel(const Model* m);
  void setInput(const string&amp; input);
  void setTagger(const string&amp; tagger);
  void setParser(const string&amp; parser);
  void setOutput(const string&amp; output);

  string process(const string&amp; data, ProcessingError* error = nullptr) const;

  static const string DEFAULT;
  static const string NONE;
};

class Trainer {
 public:

  static string train(const string&amp; method, const Sentences&amp; train, const Sentences&amp; heldout,
                      const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser,
                      ProcessingError* error = nullptr);

  static const string DEFAULT;
  static const string NONE;
};

class Evaluator {
 public:
  Evaluator(const Model* m, const string&amp; tokenizer, const string&amp; tagger, const string&amp; parser);

  void setModel(const Model* m);
  void setTokenizer(const string&amp; tokenizer);
  void setTagger(const string&amp; tagger);
  void setParser(const string&amp; parser);

  string evaluate(const string&amp; data, ProcessingError* error = nullptr) const;

  static const string DEFAULT;
  static const string NONE;
};

class Version {
 public:
  unsigned major;
  unsigned minor;
  unsigned patch;
  string prerelease;

  // Returns current version.
  static version current();
};
</pre>

<a id="csharp_bindings" name="csharp_bindings"></a>
<h2>6.14. C# Bindings</h2>

<p>
UDPipe library bindings is available in the <code>Ufal.UDPipe</code> namespace.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
The bindings requires native C++ library <code>libudpipe_csharp</code> (called
<code>udpipe_csharp</code> on Windows).
</p>

<a id="java_bindings" name="java_bindings"></a>
<h2>6.15. Java Bindings</h2>

<p>
UDPipe library bindings is available in the <code>cz.cuni.mff.ufal.udpipe</code>
package.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
Vectors do not have native Java interface, see
<code>cz.cuni.mff.ufal.udpipe.Words</code> class for reference. Also, class members
are accessible and modifiable using using <code>getField</code> and <code>setField</code>
wrappers.
</p>
<p>
The bindings require native C++ library <code>libudpipe_java</code> (called
<code>udpipe_java</code> on Windows). If the library is found in the current
directory, it is used, otherwise standard library search process is used.
</p>

<a id="perl_bindings" name="perl_bindings"></a>
<h2>6.16. Perl Bindings</h2>

<p>
UDPipe library bindings is available in the
<a href="http://search.cpan.org/~straka/Ufal-UDPipe/"><code>Ufal::UDPipe</code></a> package.
The classes can be imported into the current namespace using the <code>:all</code>
export tag.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
Vectors do not have native Perl interface, see <code>Ufal::UDPipe::Words</code> for
reference. Static methods and enumerations are available only through the
module, not through object instance.
</p>

<a id="python_bindings" name="python_bindings"></a>
<h2>6.17. Python Bindings</h2>

<p>
UDPipe library bindings is available in the
<a href="http://pypi.python.org/pypi/ufal.udpipe"><code>ufal.udpipe</code></a> module.
</p>
<p>
The bindings is a straightforward conversion of the <code>C++</code> bindings API.
In Python 2, strings can be both <code>unicode</code> and UTF-8 encoded <code>str</code>, and the
library always produces <code>unicode</code>. In Python 3, strings must be only <code>str</code>.
</p>

<a id="contact" name="contact"></a>
<h1>7. Contact</h1>

<p style="margin-bottom:0">
Authors:
</p>
<ul style="margin-top:0">
<li><a href="http://ufal.mff.cuni.cz/milan-straka">Milan Straka</a>, <a href="mailto:straka@ufal.mff.cuni.cz">straka@ufal.mff.cuni.cz</a>
</li>
</ul>

<p>
<a href="http://ufal.mff.cuni.cz/udpipe">UDPipe website</a>.
</p>
<p>
<a href="http://hdl.handle.net/11234/1-1702">UDPipe LINDAT/CLARIN entry</a>.
</p>

<a id="udpipe_acknowledgements" name="udpipe_acknowledgements"></a>
<h1>8. Acknowledgements</h1>

<p>
This work has been using language resources developed and/or stored and/or distributed by the LINDAT/CLARIN project of the Ministry of Education of the Czech Republic (project <i>LM2010013</i>).
</p>
<p>
Acknowledgements for individual language models are listed in <a href="#users_manual">UDPipe User's Manual</a>.
</p>

<a id="publications" name="publications"></a>
<h2>8.1. Publications</h2>

<ul>
<li>(Straka et al. 2016) Straka Milan, Hajič Jan, Straková Jana. <i>UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing.</i> In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), Portorož, Slovenia, May 2016.
</li>
</ul>

<a id="bibtex_for_referencing" name="bibtex_for_referencing"></a>
<h2>8.2. Bibtex for Referencing</h2>

<pre>
@InProceedings{udpipe:2016,
  author    = {Straka, Milan and Haji\v{c}, Jan and Strakov\'{a}},
  title     = {{UDPipe:} Trainable Pipeline for Processing {CoNLL-U} Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing},
  booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16),
  year      = {2016},
  month     = {May},
  date      = {23-28},
  location  = {Portorož, Slovenia},
  publisher = {European Language Resources Association (ELRA)},
  address   = {Paris, France},
  isbn      = {978-2-9517408-9-1}
}
</pre>

<a id="persistent_identifier" name="persistent_identifier"></a>
<h2>8.3. Persistent Identifier</h2>

<p>
If you prefer to reference UDPipe by a persistent identifier (PID),
you can use <code>http://hdl.handle.net/11234/1-1702</code>.
</p>
</div>

<!-- html code generated by txt2tags 2.6 (http://txt2tags.org) -->
<!-- cmdline: txt2tags -t html -\-toc -\-enum-title -o manual.html -C t2t_docsys/t2t_docsys_manual.conf manual.t2t -->
</body></html>
